import streamlit as st
import yaml
import os
import sys
import subprocess
import pathlib
import pandas as pd
import re
import json
from datetime import datetime
from process import process, delete
try:
    project_root = pathlib.Path(__file__).resolve().parents[1]
except NameError:
    project_root = pathlib.Path(os.getcwd()).resolve().parents[0]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
from models.check_utils import get_datasets_measure_names,CheckUtils
from streamlit_option_menu import option_menu


def render_scrollable_markdown(md_text, height=300):
    st.markdown(
        f"""
        <div style='height:{height}px; overflow:auto; padding:10px; border:1px solid #ccc; background-color:#f9f9f9; border-radius:5px'>
        {md_text}
        </div>
        """,
        unsafe_allow_html=True
    )
    
def set_streamlit_upload_limit(limit_mb=2048):
    config_dir = os.path.expanduser("~/.streamlit")
    os.makedirs(config_dir, exist_ok=True)
    config_path = os.path.join(config_dir, "config.toml")

    with open(config_path, "w") as f:
        f.write(f"[server]\nmaxUploadSize = {limit_mb}\n")

set_streamlit_upload_limit(2048)

st.set_page_config(layout="wide")
st.title("åˆ†å­æ€§è´¨é¢„æµ‹é›†æˆå¹³å°")
st.markdown("é›†æ¨¡å‹å’Œæ•°æ®ç®¡ç†äºä¸€ä½“ï¼Œæ”¯æŒä¸Šä¼ åˆ å‡æ¨¡å‹ï¼Œä¸€é”®å¼é€‰æ‹©ï¼Œå¤„ç†æ•°æ®ï¼Œå¹¶ä¸”å±•ç¤º")

# ----------- é…ç½®è·¯å¾„ -----------
MODEL_PATH =os.path.join(project_root,'models')
CONFIG_PATH = os.path.join(project_root,'result_analysis','config_run.yaml')
# MODEL_MAP_PATH = os.path.join(project_root,'models','model_datasets.yaml')
RUN_SCRIPT_PATH = os.path.join(project_root,'result_analysis','run_all.py')
HISTORY_PATH = os.path.join(project_root, 'results', 'results','run_history.json')
MODEL_DATASET_PATH = os.path.join(MODEL_PATH,'models.yaml')
UPLOAD_MODEL_README = os.path.join(MODEL_PATH,'models_README.md')
UPLOAD_DATA_README = os.path.join(project_root,'dataset','dataset_README.md')





# ----------- åŠ è½½ config.yaml -----------
@st.cache_data
def load_config(path=CONFIG_PATH):
    if not os.path.exists(path):
        return {
            "model": "fp",
            "name": "BBBP",
            "eval": True,
            "target_list": "all",
            "smiles_list": "random200",
            "output": "results",
            "plotpath": "plots",
            "plotprevisousruns": False
        }
    with open(path, "r") as f:
        return yaml.safe_load(f)

def get_all_model_types():
    with open(MODEL_DATASET_PATH,'r') as f:
        config = yaml.safe_load(f)
        return list(config.keys())

def get_models_and_data(top_key):  # top_key æ˜¯ 'moleculenet'
    with open(MODEL_DATASET_PATH, 'r') as f:
        config = yaml.safe_load(f)

    top_config = config.get(top_key, {})
    # æå–æ‰€æœ‰æ¨¡å‹åç»„åˆï¼Œå¦‚ FP_NN, GNN_GIN ç­‰
    models_config = top_config.get('models', {})
    model_names = []
    for model_type in models_config:
        if isinstance(models_config[model_type], dict): 
            model_names.append(model_type)
    DATACONFIG_PATH = os.path.join(project_root,'dataset','data',top_key,'dataset.yaml')
    with open(DATACONFIG_PATH, 'r',encoding='utf-8') as g:
        config = yaml.safe_load(g)
    all_datasets = config.get('dataset_names',[])

    return model_names, all_datasets
        
def get_data_type(top_key):
    DATACONFIG_PATH = os.path.join(project_root,'dataset','data',top_key,'dataset.yaml')
    with open(DATACONFIG_PATH, 'r',encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return (config.get('data_type',''))

def display_csv_tables(csv_dir):
    csv_files = [f for f in os.listdir(csv_dir) if f.endswith(".csv")]
    for csv_file in sorted(csv_files):
        csv_path = os.path.join(csv_dir, csv_file)
        with st.expander(f"ğŸ“„ {csv_file}"):
            try:
                df = pd.read_csv(csv_path)
                st.dataframe(df, use_container_width=True)
            except Exception as e:
                st.warning(f"{csv_file} åŠ è½½å¤±è´¥: {e}")
                
def display_images_recursively(base_dir):
    for root, dirs, files in os.walk(base_dir):
        image_files = [f for f in files if f.lower().endswith((".png", ".jpg", ".jpeg"))]
        if image_files:
            rel_path = os.path.relpath(root, base_dir)
            with st.expander(f"ğŸ“‚ {rel_path}"):
                cols = st.columns(2)  # æ¯è¡Œä¸¤åˆ—
                for idx, image in enumerate(sorted(image_files)):
                    image_path = os.path.join(root, image)
                    col = cols[idx % 2]  # äº¤æ›¿å†™å…¥ä¸¤ä¸ªåˆ—
                    with col:
                        st.image(image_path, caption=image, use_container_width="always")

                
def get_latest_run_folder(base="results"):
    run_dirs = [d for d in os.listdir(base) if os.path.isdir(os.path.join(base, d)) and re.match(r"run\d+", d)]
    run_numbers = [int(re.findall(r"run(\d+)", d)[0]) for d in run_dirs]
    if run_numbers:
        latest_run = f"run{max(run_numbers)}"
        return latest_run,os.path.join(base, latest_run)
    return None

def get_submodel(model_type, model):
    with open(MODEL_DATASET_PATH, 'r') as f:
        data = yaml.safe_load(f)
    
    try:
        return list(data[model_type]['models'][model].keys())
    except (KeyError, AttributeError):
        return []

        


def show_file_selector(label: str, file_path: str, is_markdown: bool = False, is_text: bool = False, height: int = 500) -> None:
    """æ˜¾ç¤ºå¤é€‰æ¡†ï¼Œå‹¾é€‰åå±•ç¤ºæ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒ markdownã€python å’Œ txt å½¢å¼ï¼Œå¸¦å›ºå®šé«˜åº¦æ»šåŠ¨æ¡"""
    if not os.path.exists(file_path):
        st.write(f"{label} æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")
        return

    show_content = st.checkbox(f"æ˜¾ç¤º {label}", key=f"show_{label}")

    if show_content:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        if is_markdown:
            render_scrollable_markdown(content, height=height)
        elif is_text:
            st.code(content, language=None, line_numbers=True, height=height)  # txt å†…å®¹æ— é«˜äº®
        else:
            st.code(content, language="python", line_numbers=True, height=height)


# ----------- ä¿å­˜ config.yaml -----------
def save_config(config, path=CONFIG_PATH):
    with open(path, "w") as f:
        yaml.safe_dump(config, f, allow_unicode=True)
        
def list_to_csv_fields(config_dict, fields):
    for field in fields:
        if isinstance(config_dict.get(field), list):
            config_dict[field] = ",".join(str(x) for x in config_dict[field])
    return config_dict


def get_datasets_for_model(model_list, model_map):
    """
    ä»æ¨¡å‹åˆ—è¡¨ä¸­æå–æ‰€æœ‰æ¨¡å‹æ”¯æŒçš„æ•°æ®é›†ï¼Œå¹¶è¿”å›å®ƒä»¬çš„äº¤é›†ã€‚

    å‚æ•°ï¼š
    - model_list (List[str]): æ¨¡å‹åç§°åˆ—è¡¨ï¼Œå¦‚ ['FP NN', 'GNN GCN']
    - model_map (Dict[str, Dict]): ä» model_datasets.yaml åŠ è½½çš„æ¨¡å‹æ˜ å°„

    è¿”å›ï¼š
    - List[str]: æ‰€æœ‰æ¨¡å‹å…±åŒæ”¯æŒçš„æ•°æ®é›†åç§°åˆ—è¡¨
    """
    all_dataset_sets = []

    for model in model_list:
        try:
            model_name= model.split("_")[0]
            model_type = model.split("_")[1]
        except ValueError:
            continue  # å¿½ç•¥æ ¼å¼é”™è¯¯çš„æ¡ç›®

        datasets = model_map.get(model_name, {}).get(model_type)
        if datasets:
            all_dataset_sets.append(set(datasets))

    if not all_dataset_sets:
        return []

    common_datasets = set.intersection(*all_dataset_sets)
    return sorted(list(common_datasets))





# ----------- åˆå§‹åŒ– session_state -----------
if "selected_model_field" not in st.session_state:
    st.session_state["selected_model_field"] = None
if "selected_models" not in st.session_state:
    st.session_state["selected_models"] = []
if "selected_datasets" not in st.session_state:
    st.session_state["selected_datasets"] = []
if "eval" not in st.session_state:
    st.session_state["eval"] = True
if "smiles_list" not in st.session_state:
    st.session_state["smiles_list"] = "random200"
if "smiles_input_mode" not in st.session_state:
    st.session_state["smiles_input_mode"] = "auto_eval"  # å¯é€‰: auto_eval, file_upload, manual_input
if "smiles_text_input" not in st.session_state:
    st.session_state["smiles_text_input"] = ""
if "smiles_file" not in st.session_state:
    st.session_state["smiles_file"] = None
if "smiles_eval_mode" not in st.session_state:
    st.session_state["smiles_eval_mode"] = "random"
if "smiles_eval_num" not in st.session_state:
    st.session_state["smiles_eval_num"] = 200
def get_top_level_keys():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    yaml_path = os.path.abspath(os.path.join(current_dir, '../environment.yaml'))

    with open(yaml_path, 'r', encoding='utf-8') as f:
        data = yaml.safe_load(f)

    if isinstance(data, dict):
        return list(data.keys())
    else:
        return []
def run_long_command(cmd, description="æ­£åœ¨æ‰§è¡Œå‘½ä»¤..."):
    import subprocess
    import time

    with st.spinner(description):
        try:
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )

            stdout, stderr = process.communicate()

            if process.returncode != 0:
                st.error("å‘½ä»¤æ‰§è¡Œå¤±è´¥ âŒ")
                if stderr:
                    st.code(stderr, language="bash")
                return False
            else:
                if stdout:
                    st.code(stdout, language="bash")
                return True
        except Exception as e:
            st.error("æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸ âŒ")
            st.exception(e)
            return False

def show_update_button(model, reqname):
    with st.expander("æ›´æ–°ç¯å¢ƒ"):
        keys = get_top_level_keys()
        if not keys:
            st.warning("environment.yaml æ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œæ— æ³•é€‰æ‹©ç¯å¢ƒåã€‚")
            return

        env_name = st.selectbox("é€‰æ‹©ç¯å¢ƒåå­—", keys)

        if st.button("Update"):
            st.text("â³ å¼€å§‹æ›´æ–°...")
            success = update(reqname, env_name, model)
            if success:
                st.success(f"âœ… Update æˆåŠŸï¼šmodel={model}, reqname={reqname}, envname={env_name}")
                st.text("è¯·é€€å‡ºå¹¶é‡æ–°æ‰“å¼€ä»¥ç”Ÿæ•ˆ")
            else:
                st.error("âŒ Update å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å‡ºä¿¡æ¯")

def update(file, envname, model):
    current_dir = os.path.dirname(os.path.abspath(__file__))
    script_path = os.path.abspath(os.path.join(current_dir, '../env_utils.py'))
    env_md_path = os.path.abspath(os.path.join(current_dir, '../environment.yaml'))

    cmd = [sys.executable, script_path, "update", '-r', file, '-e', envname]
    success = run_long_command(cmd, description=f"æ­£åœ¨æ›´æ–°ç¯å¢ƒ {envname}...")

    if not success:
        return False

    # âœ… ä¿ç•™ä½ çš„ environment.yaml å†™å…¥é€»è¾‘
    try:
        with open(env_md_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f) or {}

        if envname not in data:
            st.error(f"é”™è¯¯: environment.yaml é¡¶å±‚æ‰¾ä¸åˆ°ç¯å¢ƒå '{envname}'")
            return False

        data[envname][model] = file

        with open(env_md_path, 'w', encoding='utf-8') as f:
            yaml.safe_dump(data, f, allow_unicode=True)

        return True

    except Exception as e:
        st.error(f"å†™å…¥ environment.yaml å¤±è´¥: {e}")
        return False

def show_create_button(reqname, model):
    with st.expander("åˆ›å»ºç¯å¢ƒ"):
        st.markdown("### åˆ›å»ºæ¨¡å‹é…ç½®")
        col1, col2 = st.columns(2)

        with col1:
            py_version = st.text_input("Python ç‰ˆæœ¬", value="3.8", max_chars=10)

        with col2:
            env_name = st.text_input("ç¯å¢ƒåå­—", max_chars=20)

        if st.button("Create"):
            if not py_version.strip() or not env_name.strip():
                st.error("è¯·å¡«å†™å®Œæ•´çš„ Python ç‰ˆæœ¬å’Œç¯å¢ƒåå­—ï¼")
            else:
                create(model, reqname, env_name, py_version)
                st.text("åˆ›å»ºç¯å¢ƒä¸­")
                st.success(f"Create è°ƒç”¨æˆåŠŸï¼Œç¯å¢ƒå={env_name}, Pythonç‰ˆæœ¬={py_version}")
                st.text("åˆ›å»ºæ–°ç¯å¢ƒï¼Œè¯·é€€å‡ºé‡æ–°æ‰“å¼€")

def create(model, file, envname, version):
    current_dir = os.path.dirname(os.path.abspath(__file__))
    script_path = os.path.abspath(os.path.join(current_dir, '../env_utils.py'))
    base_reqs = os.path.abspath(os.path.join(current_dir, '../requirements.txt'))
    env_md_path = os.path.abspath(os.path.join(current_dir, '../environment.yaml'))

    cmd = [sys.executable, script_path, 'create', '-r', base_reqs, '-a', file, '-e', envname, '-p', version]

    try:
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        print("åˆ›å»ºæˆåŠŸï¼Œè¾“å‡º:")
        print(result.stdout)
    except subprocess.CalledProcessError as e:
        print(f"åˆ›å»ºå¤±è´¥ï¼Œè¿”å›ç ï¼š{e.returncode}")
        print(e.stderr)
        return

    with open(env_md_path, 'r', encoding='utf-8') as f:
        data = yaml.safe_load(f) or {}

    if envname not in data or not isinstance(data[envname], dict):
        data[envname] = {}

    data[envname][model] = file

    with open(env_md_path, 'w', encoding='utf-8') as f:
        yaml.safe_dump(data, f, allow_unicode=True)

def on_select_change():
    # é€‰æ¡†æ”¹å˜æ—¶ï¼Œå¦‚æœé€‰æ‹©â€œè‡ªå®šä¹‰è¾“å…¥â€ï¼Œä¿æŒfinal_model_typeä¸å˜ç­‰å¾…è¾“å…¥æ¡†è¾“å…¥
    # å¦åˆ™æ›´æ–°final_model_typeï¼Œå¹¶æ ‡è®°åˆ—è¡¨éœ€åˆ·æ–°
    selected = st.session_state["model_type_select"]
    if selected != "è‡ªå®šä¹‰è¾“å…¥":
        if st.session_state.get("final_model_type", "") != selected:
            st.session_state["final_model_type"] = selected
            st.session_state["model_list_changed"] = True

def on_custom_input_change():
    # è‡ªå®šä¹‰è¾“å…¥æ¡†æ”¹å˜æ—¶ï¼Œæ›´æ–°final_model_typeå¹¶æ ‡è®°åˆ·æ–°
    text = st.session_state.get("custom_model_input", "").strip()
    if st.session_state.get("final_model_type", "") != text:
        st.session_state["final_model_type"] = text
        st.session_state["model_list_changed"] = True

# é¡¶éƒ¨æŒ‰é’®
if "final_model_type" not in st.session_state:
    st.session_state["final_model_type"] = ""
if "uploaded_model_zip" not in st.session_state:
    st.session_state["uploaded_model_zip"] = None
if "uploaded_model_config" not in st.session_state:
    st.session_state["uploaded_model_config"] = None
if "uploaded_data_zip" not in st.session_state:
    st.session_state["uploaded_data_zip"] = None
if "uploaded_data_config" not in st.session_state:
    st.session_state["uploaded_data_config"] = None
if "show_model_input" not in st.session_state:
    st.session_state["show_model_input"] = False
if "model_list_changed" not in st.session_state:
    st.session_state["model_list_changed"] = True

# ----------- å±•å¼€æŒ‰é’® -----------
close_tab_js = """
<script>
    window.close();
</script>
"""
exit_col_space, exit_col_btn = st.columns([9, 1])
with exit_col_btn:
    if st.button("é€€âŒå‡º"):
        st.warning("ç¨‹åºå³å°†å…³é—­...")
        st.components.v1.html(close_tab_js)
        os._exit(0)


col1, col2 = st.columns([10, 2])
with col2:
    if st.button("â• æ·»åŠ æ•°æ®é›†ä¸æ¨¡å‹ï¼ˆå†ç‚¹å‡»ä¸€æ¬¡ä»¥è¿”å›ï¼‰"):
        st.session_state["show_model_input"] = not st.session_state["show_model_input"]

# ----------- å±•å¼€åŒºåŸŸ -----------
if st.session_state.get("show_model_input", True):

    st.markdown("#### ğŸ”§ è‡ªå®šä¹‰æ•°æ®é›†ç±»å‹ä¸æ¨¡å‹åŒ…ä¸Šä¼ ")
    st.markdown("** æ³¨æ„ï¼Œå¦‚æœæ¨¡å‹ä¾èµ–pythonåº“ï¼Œè¯·åœ¨ç»ˆç«¯è‡ªè¡Œå®‰è£…ä»¥é¿å…å†²çª")

    # ä¸Šä¼ è¯´æ˜æ–‡ä»¶å±•ç¤º
    if os.path.exists(UPLOAD_MODEL_README):
        with open(UPLOAD_MODEL_README, "r", encoding="utf-8") as f:
            model_readme_text = f.read()
        with st.expander("ğŸ“˜ æŸ¥çœ‹æ¨¡å‹ä¸Šä¼ è¯´æ˜ (MODEL_readme.md)"):
            render_scrollable_markdown(model_readme_text, height=600)

    if os.path.exists(UPLOAD_DATA_README):
        with open(UPLOAD_DATA_README, "r", encoding="utf-8") as f:
            data_readme_text = f.read()
        with st.expander("ğŸ“— æŸ¥çœ‹æ•°æ®ä¸Šä¼ è¯´æ˜ (DATASET_readme.md)"):
            render_scrollable_markdown(data_readme_text, height=600)

    # è·å–æ‰€æœ‰æ¨¡å‹ç±»å‹
    try:
        all_model_types = get_all_model_types()
    except Exception as e:
        st.warning(f"åŠ è½½æ•°æ®é›†ç±»å‹å¤±è´¥ï¼š{e}")
        all_model_types = []

    model_type_options = ["è‡ªå®šä¹‰è¾“å…¥"] + all_model_types

    # è®¡ç®—å½“å‰é€‰ä¸­indexï¼Œé»˜è®¤é€‰è‡ªå®šä¹‰è¾“å…¥
    if st.session_state["final_model_type"] in all_model_types:
        current_index = model_type_options.index(st.session_state["final_model_type"])
    else:
        current_index = 0

    selected_option = st.selectbox(
        "ä»å·²æœ‰æ•°æ®é›†ç±»å‹ä¸­é€‰æ‹©æˆ–ç›´æ¥è¾“å…¥æ–°ç±»å‹ï¼š",
        options=model_type_options,
        index=current_index,
        key="model_type_select",
        on_change=on_select_change,
    )

    if selected_option == "è‡ªå®šä¹‰è¾“å…¥":
        custom_input = st.text_input(
            "è¯·è¾“å…¥æ–°çš„æ•°æ®é›†ç±»å‹å¹¶å›è½¦",
            value=st.session_state.get("custom_model_input", ""),
            key="custom_model_input",
            on_change=on_custom_input_change,
        )
    else:
        if "custom_model_input" in st.session_state:
            del st.session_state["custom_model_input"]

    if selected_option != "è‡ªå®šä¹‰è¾“å…¥" and st.session_state.get("final_model_type"):

        if st.session_state["model_list_changed"]:
            # åªæœ‰éè‡ªå®šä¹‰è¾“å…¥ï¼Œä¸”åˆ—è¡¨æ”¹å˜æ—¶ï¼ŒåŠ è½½åˆ—è¡¨
            models_list, datasets_list = get_models_and_data(st.session_state["final_model_type"])
            st.session_state["models_list"] = models_list
            st.session_state["datasets_list"] = datasets_list
            st.session_state["model_list_changed"] = False

        datatype = get_data_type(st.session_state["final_model_type"])
        st.markdown(f"**ğŸ§¬ å¯¹åº”çš„æ•°æ®è¾“å…¥æ ¼å¼ï¼š** `{datatype}`")

        if st.session_state.get("models_list"):
            with st.expander("ğŸ“¦ å·²æœ‰æ¨¡å‹åˆ—è¡¨ (models_list)"):
                for model_name in st.session_state["models_list"]:
                    cols = st.columns([4, 1])
                    cols[0].markdown(f"- {model_name}")
                    if cols[1].button("ğŸ—‘ï¸ åˆ é™¤", key=f"del_{model_name}"):
                        delete(st.session_state["final_model_type"], model_name)
                        st.session_state["model_list_changed"] = True

        if st.session_state.get("datasets_list"):
            with st.expander("ğŸ—‚ï¸ å·²æœ‰æ•°æ®é›†åˆ—è¡¨ (datasets_list)"):
                st.markdown("\n".join(f"- {item}" for item in st.session_state["datasets_list"]))
    final_model_type = st.session_state.final_model_type

    # ----------- ä¸Šä¼ æ–‡ä»¶åŒºåŸŸ -----------
    uploaded_zip = st.file_uploader(f"ğŸ“¦ ä¸Šä¼ æ¨¡å‹æ–‡ä»¶åŒ…ï¼ˆmodel.zipï¼‰ï¼Œè¿‡å¤§æ–‡ä»¶è¯·æ‰‹åŠ¨è§£å‹ç¼©å¹¶æ”¾å…¥molplat_form/dataset/data/ä½ é€‰æ‹©çš„æ¨¡å‹ç±»å‹ ç›®å½•ä¸‹ï¼ˆmolplat_form/dataset/data/{final_model_type}ï¼‰", type=["zip"])
    if uploaded_zip:
        st.session_state["uploaded_model_zip"] = uploaded_zip
        st.success(f"âœ… ä¸Šä¼ æ¨¡å‹åŒ…ï¼š{uploaded_zip.name}")

    uploaded_model_config = st.file_uploader("ğŸ“„ ä¸Šä¼ æ¨¡å‹é…ç½®æ–‡ä»¶ï¼ˆmodel_config.yamlï¼‰", type=["yaml"])
    if uploaded_model_config:
        st.session_state["uploaded_model_config"] = uploaded_model_config
        st.success(f"âœ… ä¸Šä¼ æ¨¡å‹é…ç½®ï¼š{uploaded_model_config.name}")
        
    uploaded_data_config = st.file_uploader("ğŸ“„ ä¸Šä¼ æ•°æ®é…ç½®æ–‡ä»¶ï¼ˆdata_config.yamlï¼‰", type=["yaml"])
    if uploaded_data_config:
        st.session_state["uploaded_data_config"] = uploaded_data_config
        st.success(f"âœ… ä¸Šä¼ æ•°æ®é…ç½®ï¼š{uploaded_data_config.name}")

    uploaded_data_zip = st.file_uploader(f"ğŸ—‚ï¸ ä¸Šä¼ æ•°æ®æ–‡ä»¶åŒ…ï¼ˆdata.zipï¼‰ï¼Œè¿‡å¤§æ–‡ä»¶è¯·æ‰‹åŠ¨è§£å‹ç¼©å¹¶æ”¾å…¥molplat_form/models/ä½ é€‰æ‹©çš„æ¨¡å‹ç±»å‹ ç›®å½•ä¸‹ ï¼ˆmolplat_form/models/{final_model_type}ï¼‰", type=["zip"])
    if uploaded_data_zip:
        st.session_state["uploaded_data_zip"] = uploaded_data_zip
        st.success(f"âœ… ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼š{uploaded_data_zip.name}")

    # ----------- æ˜¾ç¤ºç”¨æˆ·è¾“å…¥çŠ¶æ€ -----------
    if final_model_type:
        st.success(f"ğŸ¯ é€‰æ‹©/è¾“å…¥çš„æ•°æ®é›†ç±»å‹ï¼š`{final_model_type}`")
    if st.button("ğŸš€ æäº¤å¹¶å¤„ç†"):
        if st.session_state.model_type_select == "è‡ªå®šä¹‰è¾“å…¥" and not st.session_state.final_model_type.strip():
            st.warning("âš ï¸ è¯·è¾“å…¥è‡ªå®šä¹‰æ•°æ®é›†ç±»å‹åç§°åå†æäº¤ã€‚")
        else:# è·å–ä¸Šä¼ çš„æ–‡ä»¶
            model_zip = st.session_state.get("uploaded_model_zip")
            model_config = st.session_state.get("uploaded_model_config")
            data_zip = st.session_state.get("uploaded_data_zip")
            data_config = st.session_state.get("uploaded_data_config")

            # æ£€æŸ¥æ¨¡å‹ç»„æ˜¯å¦å®Œæ•´
            model_ready = (model_zip is not None) and (model_config is not None)
            # æ£€æŸ¥æ•°æ®ç»„æ˜¯å¦å®Œæ•´
            data_ready = (data_zip is not None) and (data_config is not None)
            all_configs = (model_config is not None ) and (data_config is not None)

            # æƒ…å†µ1ï¼šæ¨¡å‹ç»„å®Œæ•´ï¼Œdata_zip å¯ä»¥ç¼ºå¤±ï¼ˆä½† data_config å¿…é¡»ä¼ ï¼‰
            condition1 = model_ready and (data_config is not None)
            # æƒ…å†µ2ï¼šæ•°æ®ç»„å®Œæ•´ï¼Œæ¨¡å‹ç»„å¯ä»¥å®Œå…¨ç¼ºå¤±
            condition2 = data_ready and (not model_ready)
            condition3 = model_ready and data_ready

            if condition1 or condition2 or condition3 or all_configs:
                # âœ… æ»¡è¶³æ¡ä»¶ï¼Œè°ƒç”¨ process
                result = process(
                    final_model_type,
                    model_zip,
                    model_config,
                    data_zip,
                    data_config
                )
                
                if result is True:
                    st.success("âœ… æ¨¡å‹å¯¼å…¥å®Œæˆï¼")
                else:
                    st.error(result)
            else:
                # âŒ ä¸æ»¡è¶³æ¡ä»¶ï¼Œæç¤ºé”™è¯¯
                missing = []
                if not model_ready:
                    missing.append("æ¨¡å‹ç»„ï¼ˆéœ€åŒæ—¶ä¸Šä¼  model_zip å’Œ model_configï¼‰")
                if data_config is None:
                    missing.append("data_configï¼ˆå¿…é¡»ä¸Šä¼ ï¼‰")
                if not data_ready and (data_zip is not None or data_config is not None):
                    missing.append("æ•°æ®ç»„ä¸å®Œæ•´ï¼ˆéœ€åŒæ—¶ä¸Šä¼  data_zip å’Œ data_configï¼‰")

                st.error(f"""
                âš ï¸ **æäº¤å¤±è´¥ï¼**  
                è¯·ç¡®ä¿ç¬¦åˆä»¥ä¸‹æ¡ä»¶ä¹‹ä¸€ï¼š
                - **æƒ…å†µ1**ï¼šå®Œæ•´ä¸Šä¼ æ¨¡å‹ç»„ï¼ˆ`model_zip` + `model_config`ï¼‰ï¼Œå¹¶è‡³å°‘ä¸Šä¼  `data_config`ï¼ˆ`data_zip` å¯é€‰ï¼‰ï¼Œ**æˆ–**  
                - **æƒ…å†µ2**ï¼šå®Œæ•´ä¸Šä¼ æ•°æ®ç»„ï¼ˆ`data_zip` + `data_config`ï¼‰ï¼Œä¸ä¸Šä¼ æ¨¡å‹ç»„ï¼Œ**æˆ–** 
                - **æƒ…å†µ3**: å…¨éƒ¨å®Œæ•´ä¸Šä¼  ï¼Œ**æˆ–** 
                - **æƒ…å†µ4**: ä¸Šä¼ config å¹¶å°†å…¶ä½™æ–‡ä»¶æ”¾å…¥å¯¹åº”æ–‡ä»¶å¤¹ä¸‹


                """)
else:
    # ----------- å½“ model_field å˜åŒ–æ—¶ï¼Œé‡ç½®æ‰€æœ‰ç›¸å…³é€‰æ‹© -----------
    def on_model_field_change():
        st.session_state["selected_models"] = []
        st.session_state["selected_datasets"] = []
        st.session_state["selected_tasks"] = []
        st.session_state["_last_selected_dataset"] = None
        
    model_field_options = get_all_model_types()  # æŒ‰ä½ çš„éœ€æ±‚å¯æ‰©å±•æˆ–è‡ªåŠ¨åŠ è½½

    # âœ… æ·»åŠ æ¨¡å‹ç‰¹å¾å­—æ®µé€‰æ‹©æ§ä»¶
    st.selectbox(
        "æ¨¡å‹æ‰€å±æ•°æ®é›†ç±»å‹",
        options=model_field_options,
        key="selected_model_field",
        on_change=on_model_field_change
    )    
    # ----------- ä» model_dataset_map.yaml è·å–æ•°æ®é›†åˆ—è¡¨ -----------
    @st.cache_data
    def load_model_map(modelfield, path=MODEL_PATH):
        new_path = os.path.join(path, 'models.yaml')
        with open(new_path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)

        return data.get(modelfield, {}).get("models", {})

    model_field = st.session_state["selected_model_field"]
    if model_field:
        model_options =[]
        model_map = load_model_map(model_field)
        for mode_l in model_map:
            submodels = get_submodel(model_field,mode_l)
            for submodel in submodels:
                full_model = f"{mode_l}_{submodel}"
                model_options.append(full_model)
        model_options_with_all = model_options + ["all"]
        # ----------- è®°å½•æ¨¡å‹é€‰æ‹©å‰çš„å€¼ -----------


        def on_model_change():
            st.session_state["selected_datasets"] = []
            st.session_state["selected_tasks"] = []

        # âœ… å¤šé€‰æ§ä»¶ï¼ˆä½¿ç”¨ session ä¿å­˜ + å›è°ƒé‡ç½®ï¼‰
        st.multiselect(
            "æ¨¡å‹åç§°(model)",
            options=model_options_with_all,
            key="selected_models",
            on_change=on_model_change
        )

    if "all" in st.session_state["selected_models"]:
        model = model_options
    else:
        model = st.session_state["selected_models"]
        

    if model:
        model_upper_list =[]
        for models in model:
            if isinstance(models, str) and "_" in models:
                model_part = models.split("_")[0]
            else:
                model_part = str(models).upper()
            if model_part not in model_upper_list:
                model_upper_list.append(model_part)
                readname = f"{model_part}_readme.md"
                outputname = f"{model_part}_output.py"
                dataname = f"{model_part}_data.py"
                modelname = f"{model_part}_model.py"
                reqname =  f"{model_part}_requirements.txt"
                READMEFILE_PATH = os.path.join(project_root, 'models',model_field,readname)
                OUTPUTFILE_PATH = os.path.join(project_root, 'models',model_field,model_part,outputname)
                DATAFILE_PATH = os.path.join(project_root, 'models',model_field,model_part,dataname)
                MODELFILE_PATH=os.path.join(project_root, 'models',model_field,model_part,modelname)
                REQ_PATH = os.path.join(project_root, 'models',model_field,reqname)
                show_file_selector(f"{model_part}: requirements.txt", REQ_PATH, is_text=True)
                show_update_button(model_part, reqname)
                show_create_button(model_part,reqname)
                show_file_selector(f"{model_part}: README.md", READMEFILE_PATH, is_markdown=True)
                show_file_selector(f"{model_part}: Output Script", OUTPUTFILE_PATH)
                show_file_selector(f"{model_part}: Data Script", DATAFILE_PATH)
                show_file_selector(f"{model_part}: Model Script", MODELFILE_PATH)
    #--------datasets åªæœ‰åœ¨ model å‡ºç°çš„æ—¶å€™å†å‡ºç°
    def on_dataset_change():
        st.session_state["selected_tasks"] = []  # é‡ç½®ä»»åŠ¡é€‰æ‹©
        st.session_state["_last_selected_dataset"] = None  # æ¸…é™¤ä¸Šæ¬¡ä»»åŠ¡çš„ç¼“å­˜æ ‡è®°

    if "selected_datasets" not in st.session_state:
        st.session_state["selected_datasets"] = []

    if model:
        available_datasets = get_datasets_for_model(model, model_map)
        dataset_options_with_all = available_datasets + ["all"]

        st.multiselect(
            "æ•°æ®é›†åç§° (name)",
            options=dataset_options_with_all,
            key="selected_datasets",
            on_change=on_dataset_change
        )

        if "all" in st.session_state["selected_datasets"]:
            name = available_datasets
        else:
            name = st.session_state["selected_datasets"]

    # ----------- ä»»åŠ¡é€‰æ‹©ï¼ˆtarget_listï¼‰-----------
    if "selected_tasks" not in st.session_state:
        st.session_state["selected_tasks"] = []

    if "name" in locals() and name:
        if len(name) > 1:
            st.markdown("**ä»»åŠ¡åç§° (target_list):** all")
            target_list = "all"
        else:
            dataset_name = name[0]

            try:
                utils = CheckUtils(st.session_state["selected_model_field"])
                available_tasks = utils.get_datasets_measure_names(dataset_name)
                task_options_with_all = available_tasks + ["all"]

                # å¦‚æœæ¢äº†æ•°æ®é›†ï¼Œé‡ç½®ä»»åŠ¡é€‰æ‹©
                if st.session_state.get("_last_selected_dataset") != dataset_name:
                    st.session_state["selected_tasks"] = []
                    st.session_state["_last_selected_dataset"] = dataset_name

                st.multiselect(
                    "ä»»åŠ¡åç§° (target_list)",
                    options=task_options_with_all,
                    key="selected_tasks"
                )

                if "all" in st.session_state["selected_tasks"]:
                    target_list = available_tasks
                else:
                    target_list = st.session_state["selected_tasks"]

            except Exception as e:
                st.warning(f"æ— æ³•è·å–ä»»åŠ¡åˆ—è¡¨ï¼š{e}")
                target_list = "all"


    # ----------- evaluation è¾“å…¥æ¡† -----------
    if "eval" not in st.session_state:
        st.session_state["eval"] = True
    eval = st.checkbox("æ˜¯å¦è¯„ä¼°æ¨¡å‹å¹¶ç»˜å›¾ (å¿…é¡»å…ˆä¸Šä¼ æ•°æ®)", key="eval")

    # ----------- smiles_list è¾“å…¥æ¡† -----------
    if "smiles_list" not in st.session_state:
        st.session_state["smiles_list"] = "random200"
    st.markdown("### é€‰æ‹©æ•°æ®è¾“å…¥æ–¹å¼")
    mode_display_to_internal = {
        "è‡ªåŠ¨è¯„ä¼°(å¿…é¡»å…ˆä¸Šä¼ å¯¹åº”æ•°æ®)": "auto_eval",
        "ä¸Šä¼ æ–‡ä»¶": "file_upload",
        "æ‰‹åŠ¨è¾“å…¥": "manual_input"
    }
    mode_internal_to_display = {v: k for k, v in mode_display_to_internal.items()}

    # æ§ä»¶ï¼šé€‰æ‹©æ¨¡å¼ï¼ˆåªè¯»ï¼Œä¸ç›´æ¥æ”¹ session_stateï¼‰
    selected_mode_display = st.radio(
        "è¯·é€‰æ‹©ä¸€ç§æ–¹å¼",
        options=list(mode_display_to_internal.keys()),
        index=list(mode_display_to_internal.values()).index(st.session_state["smiles_input_mode"])
    )

    # å°† radio æ§ä»¶ç»“æœå†™å…¥ session
    if mode_display_to_internal[selected_mode_display] != st.session_state["smiles_input_mode"]:
        st.session_state["smiles_input_mode"] = mode_display_to_internal[selected_mode_display]
        st.rerun()

    # ä¸‰ç§æ¨¡å¼åˆ†åˆ«å¤„ç†
    mode = st.session_state["smiles_input_mode"]

    if mode == "auto_eval":
        smiles_eval_mode = st.selectbox(
            "é€‰æ‹©è¯„ä¼°æ¨¡å¼",
            ["random", "all"],
            index=["random", "all"].index(st.session_state["smiles_eval_mode"])
        )

        if smiles_eval_mode != st.session_state["smiles_eval_mode"]:
            st.session_state["smiles_eval_mode"] = smiles_eval_mode
            st.rerun()

        if st.session_state["smiles_eval_mode"] == "random":
            smiles_eval_num = st.number_input("è¯·è¾“å…¥è¦éšæœºé€‰æ‹©çš„æ•°é‡", min_value=1, value=st.session_state["smiles_eval_num"])
            if smiles_eval_num != st.session_state["smiles_eval_num"]:
                st.session_state["smiles_eval_num"] = smiles_eval_num
                st.session_state["smiles_list"] = f"random{smiles_eval_num}"
            else:
                st.session_state["smiles_list"] = f"random{st.session_state['smiles_eval_num']}"
        else:
            st.session_state["smiles_list"] = "all"

    elif mode == "file_upload":
        uploaded_file = st.file_uploader("ä¸Šä¼ åŒ…å« æ•°æ® çš„ .txt æˆ– .csv æ–‡ä»¶", type=["txt", "csv"])
        if uploaded_file is not None:
            st.session_state["smiles_file"] = uploaded_file
            if uploaded_file.name.endswith(".txt"):
                content = uploaded_file.read().decode("utf-8")
                lines = [line.strip() for line in content.splitlines() if line.strip()]
                st.session_state["smiles_list"] = lines
            elif uploaded_file.name.endswith(".csv"):
                df = pd.read_csv(uploaded_file)
                col = st.selectbox("é€‰æ‹©æ•°æ®æ‰€åœ¨åˆ—", df.columns)
                smiles = df[col].dropna().astype(str).tolist()
                st.session_state["smiles_list"] = smiles

    elif mode == "manual_input":
        text = st.text_area("è¯·è¾“å…¥é€—å·åˆ†éš”çš„æ•°æ®", value=st.session_state["smiles_text_input"])
        if text != st.session_state["smiles_text_input"]:
            st.session_state["smiles_text_input"] = text
            smiles = [s.strip() for s in text.split(",") if s.strip()]
            st.session_state["smiles_list"] = smiles


    # ----------- è¿è¡ŒæŒ‰é’® -----------
    if st.button("è¿è¡Œæ¨¡å‹é…ç½®å¹¶ä¿å­˜é…ç½®æ–‡ä»¶"):
        fields_to_convert = ["model", "name", "target_list"]
        config = load_config()
        config["user_argument"] = st.session_state["selected_model_field"]
        config["model"] = model
        config["name"] = name
        config["target_list"] = target_list
        config["eval"] = st.session_state["eval"]
        smiles_val = st.session_state.get("smiles_list", "")
        if isinstance(smiles_val, list):
            config["smiles_list"] = ",".join(smiles_val)
        else:
            config["smiles_list"] = smiles_val
        config = list_to_csv_fields(config, fields_to_convert)

        save_config(config)
        st.success("é…ç½®å·²ä¿å­˜ï¼")

        try:
            # è¿è¡Œå­è¿›ç¨‹å¹¶æ•è·è¾“å‡º
            result = subprocess.run(
                ["python", RUN_SCRIPT_PATH],
                capture_output=True,  # æ•è·æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯è¾“å‡º
                text=True,            # ä»¥æ–‡æœ¬å½¢å¼è¿”å›
                encoding='utf-8',     # æŒ‡å®šç¼–ç 
                check=True            # å¦‚æœè¿”å›éé›¶çŠ¶æ€ç åˆ™å¼•å‘å¼‚å¸¸
            )
            st.success("âœ… æ¨¡å‹è¿è¡Œå®Œæˆï¼")
            
            # å¤„ç†æˆåŠŸè¿è¡Œåçš„é€»è¾‘...
            result_path = os.path.join(project_root,'results','results')
            run_id,latest_run_path = get_latest_run_folder(result_path)
            history_record = {
                "timestamp": datetime.now().isoformat(),
                "run_id": run_id,
                "model_argument": config["user_argument"],
                "model": config["model"],
                "dataset": config["name"],
                "task": config["target_list"],
                "data": config["smiles_list"],
                "eval": config["eval"]
            }
            history_list = []
            if os.path.exists(HISTORY_PATH):
                with open(HISTORY_PATH, "r", encoding="utf-8") as f:
                    history_list = json.load(f)
            history_list.insert(0, history_record)
            with open(HISTORY_PATH, "w", encoding="utf-8") as f:
                json.dump(history_list, f, indent=2, ensure_ascii=False)

            if latest_run_path:
                if config['eval']:
                    plot_dir = os.path.join(latest_run_path, "plots")
                    st.markdown("## ğŸ–¼ï¸ æ¨¡å‹åˆ†æå›¾ (plots)")
                    display_images_recursively(plot_dir)

                st.markdown("## ğŸ“Š æ¨¡å‹ç»“æœè¡¨æ ¼ (CSVs)")
                display_csv_tables(latest_run_path)
            else:
                st.warning("æœªæ‰¾åˆ°ä»»ä½• runXX ç»“æœç›®å½•ã€‚")

        except subprocess.CalledProcessError as e:
            # å½“å‘½ä»¤è¿”å›éé›¶çŠ¶æ€ç æ—¶ï¼Œæ˜¾ç¤ºè¯¦ç»†é”™è¯¯
            error_msg = f"âŒ æ¨¡å‹è¿è¡Œå¤±è´¥ (è¿”å›ç : {e.returncode})!\n\n" 
            error_msg += "=== é”™è¯¯è¯¦æƒ… ===\n"
            error_msg += e.stderr + "\n"
            error_msg += "è¯·æ£€æŸ¥æ¨¡å‹ç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½® ï¼ˆmodel: README.mdï¼‰"
            st.error(error_msg)
            
            # åœ¨ç»ˆç«¯æ‰“å°å®Œæ•´é”™è¯¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            print("="*80)
            print(f"å­è¿›ç¨‹è¯¦ç»†é”™è¯¯ä¿¡æ¯ (è¿”å›ç  {e.returncode}):")
            print(e.stderr)
            print("="*80)
            
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸
            st.error(f"è¿è¡Œå‡ºé”™ï¼š{e}")
            print(f"è¿è¡Œå‡ºé”™ï¼š{e}")

    if os.path.exists(HISTORY_PATH):
        with open(HISTORY_PATH, "r", encoding="utf-8") as f:
            history_list = json.load(f)

        if history_list:
            st.markdown("---")
            st.markdown("### ğŸ“‚ å†å²è¿è¡Œè®°å½•ï¼ˆå¯ä»¥åœ¨results/resultsä¸‹æŸ¥çœ‹æ¯ä¸€æ¬¡çš„å…·ä½“ç»“æœï¼‰")
            history_labels = [f"{h['run_id']} | æ•°æ®é›†ç±»å‹ï¼š{h['model_argument']}|æ¨¡å‹: {h['model']} | æ•°æ®é›†: {h['dataset']} | ä»»åŠ¡: {h['task']}| æ•°æ®:{h['data']}" for h in history_list]
            selected_index = st.selectbox("é€‰æ‹©å†å²è®°å½•è¿è¡Œ ID ä»¥æŸ¥çœ‹ç»“æœï¼š", options=list(range(len(history_list))), format_func=lambda i: history_labels[i])

            selected = history_list[selected_index]
            selected_run_path = os.path.join(project_root, 'results', 'results', selected["run_id"])

            if os.path.exists(selected_run_path):
                if selected.get("eval", True):
                    st.markdown("## ğŸ–¼ï¸ æ¨¡å‹åˆ†æå›¾ (plots)")
                    display_images_recursively(os.path.join(selected_run_path, "plots"))

                st.markdown("## ğŸ“Š æ¨¡å‹ç»“æœè¡¨æ ¼ (CSVs)")
                display_csv_tables(selected_run_path)
            else:
                st.warning("æ‰¾ä¸åˆ°å¯¹åº”çš„å†å²ç›®å½•ã€‚")
        
            
    
