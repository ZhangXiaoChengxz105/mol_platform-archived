import streamlit as st
import yaml
import os
import sys
import subprocess
import pathlib
import pandas as pd
import re
import json
import shutil
from datetime import datetime
from process import process, delete
try:
    project_root = pathlib.Path(__file__).resolve().parents[1]
except NameError:
    project_root = pathlib.Path(os.getcwd()).resolve().parents[0]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
from models.check_utils import get_datasets_measure_names,CheckUtils
from streamlit_option_menu import option_menu


def render_scrollable_markdown(md_text, height=300):
    st.markdown(
        f"""
        <div style='height:{height}px; overflow:auto; padding:10px; border:1px solid #ccc; background-color:#f9f9f9; border-radius:5px'>
        {md_text}
        </div>
        """,
        unsafe_allow_html=True
    )
    
def set_streamlit_upload_limit(limit_mb=2048):
    config_dir = os.path.expanduser("~/.streamlit")
    os.makedirs(config_dir, exist_ok=True)
    config_path = os.path.join(config_dir, "config.toml")

    with open(config_path, "w") as f:
        f.write(f"[server]\nmaxUploadSize = {limit_mb}\n")

set_streamlit_upload_limit(2048)

st.set_page_config(layout="wide")
st.title("åˆ†å­æ€§è´¨é¢„æµ‹é›†æˆå¹³å°")
st.markdown("**ä¸€ç«™å¼AIåŒ–å­¦å¹³å°** - æ¨¡å‹ä¸æ•°æ®ç®¡ç†ã€å…¼å®¹ç¯å¢ƒæ­å»ºã€æ™ºèƒ½é¢„æµ‹è¯„ä¼°ã€å¯è§†åŒ–åˆ†æ")

# ----------- é…ç½®è·¯å¾„ -----------
MODEL_PATH =os.path.join(project_root,'models')
CONFIG_PATH = os.path.join(project_root,'result_analysis','config_run.yaml')
# MODEL_MAP_PATH = os.path.join(project_root,'models','model_datasets.yaml')
RUN_SCRIPT_PATH = os.path.join(project_root,'result_analysis','run_all.py')
HISTORY_PATH = os.path.join(project_root, 'results', 'results','run_history.json')
MODEL_DATASET_PATH = os.path.join(MODEL_PATH,'models.yaml')
UPLOAD_MODEL_README = os.path.join(MODEL_PATH,'models_README.md')
UPLOAD_DATA_README = os.path.join(project_root,'dataset','dataset_README.md')





# ----------- åŠ è½½ config.yaml -----------
@st.cache_data
def load_config(path=CONFIG_PATH):
    if not os.path.exists(path):
        return {
            "model": "fp",
            "name": "BBBP",
            "eval": True,
            "target_list": "all",
            "smiles_list": "random200",
            "output": "results",
            "plotpath": "plots",
            "plotprevisousruns": False
        }
    with open(path, "r") as f:
        return yaml.safe_load(f)

def get_all_model_types():
    with open(MODEL_DATASET_PATH,'r') as f:
        config = yaml.safe_load(f)
        return list(config.keys())

def get_models_and_data(top_key):  # top_key æ˜¯ 'moleculenet'
    with open(MODEL_DATASET_PATH, 'r') as f:
        config = yaml.safe_load(f)

    top_config = config.get(top_key, {})
    # æå–æ‰€æœ‰æ¨¡å‹åç»„åˆï¼Œå¦‚ FP_NN, GNN_GIN ç­‰
    models_config = top_config.get('models', {})
    model_names = []
    for model_type in models_config:
        if isinstance(models_config[model_type], dict): 
            model_names.append(model_type)
    DATACONFIG_PATH = os.path.join(project_root,'dataset','data',top_key,'dataset.yaml')
    with open(DATACONFIG_PATH, 'r',encoding='utf-8') as g:
        config = yaml.safe_load(g)
    all_datasets = config.get('dataset_names',[])

    return model_names, all_datasets
        
def get_data_type(top_key):
    DATACONFIG_PATH = os.path.join(project_root,'dataset','data',top_key,'dataset.yaml')
    with open(DATACONFIG_PATH, 'r',encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return (config.get('data_type',''))

def display_csv_tables(csv_dir):
    csv_files = [f for f in os.listdir(csv_dir) if f.endswith(".csv")]
    for csv_file in sorted(csv_files):
        csv_path = os.path.join(csv_dir, csv_file)
        with st.expander(f"ğŸ“„ {csv_file}"):
            try:
                df = pd.read_csv(csv_path)
                st.dataframe(df, use_container_width=True)
            except Exception as e:
                st.warning(f"{csv_file} åŠ è½½å¤±è´¥: {e}")
                
def display_images_recursively(base_dir):
    for root, dirs, files in os.walk(base_dir):
        image_files = [f for f in files if f.lower().endswith((".png", ".jpg", ".jpeg"))]
        if image_files:
            rel_path = os.path.relpath(root, base_dir)
            with st.expander(f"ğŸ“‚ {rel_path}"):
                cols = st.columns(2)  # æ¯è¡Œä¸¤åˆ—
                for idx, image in enumerate(sorted(image_files)):
                    image_path = os.path.join(root, image)
                    col = cols[idx % 2]  # äº¤æ›¿å†™å…¥ä¸¤ä¸ªåˆ—
                    with col:
                        st.image(image_path, caption=image, use_container_width="always")

                
def get_latest_run_folder(base="results"):
    run_dirs = [d for d in os.listdir(base) if os.path.isdir(os.path.join(base, d)) and re.match(r"run\d+", d)]
    run_numbers = [int(re.findall(r"run(\d+)", d)[0]) for d in run_dirs]
    if run_numbers:
        latest_run = f"run{max(run_numbers)}"
        return latest_run,os.path.join(base, latest_run)
    return None

def get_submodel(model_type, model):
    with open(MODEL_DATASET_PATH, 'r') as f:
        data = yaml.safe_load(f)
    
    try:
        return list(data[model_type]['models'][model].keys())
    except (KeyError, AttributeError):
        return []

        


def show_file_selector(label: str, file_path: str, is_markdown: bool = False, is_text: bool = False, height: int = 500) -> None:
    """æ˜¾ç¤ºå¤é€‰æ¡†ï¼Œå‹¾é€‰åå±•ç¤ºæ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒ markdownã€python å’Œ txt å½¢å¼ï¼Œå¸¦å›ºå®šé«˜åº¦æ»šåŠ¨æ¡"""
    if not os.path.exists(file_path):
        st.write(f"{label} æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")
        return

    show_content = st.checkbox(f"æ˜¾ç¤º {label}", key=f"show_{label}")

    if show_content:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        if is_markdown:
            render_scrollable_markdown(content, height=height)
        elif is_text:
            st.code(content, language=None, line_numbers=True, height=height)  # txt å†…å®¹æ— é«˜äº®
        else:
            st.code(content, language="python", line_numbers=True, height=height)


# ----------- ä¿å­˜ config.yaml -----------
def save_config(config, path=CONFIG_PATH):
    with open(path, "w") as f:
        yaml.safe_dump(config, f, allow_unicode=True)
        
def list_to_csv_fields(config_dict, fields):
    for field in fields:
        if isinstance(config_dict.get(field), list):
            config_dict[field] = ",".join(str(x) for x in config_dict[field])
    return config_dict


def get_datasets_for_model(model_list, model_map):
    """
    ä»æ¨¡å‹åˆ—è¡¨ä¸­æå–æ‰€æœ‰æ¨¡å‹æ”¯æŒçš„æ•°æ®é›†ï¼Œå¹¶è¿”å›å®ƒä»¬çš„äº¤é›†ã€‚

    å‚æ•°ï¼š
    - model_list (List[str]): æ¨¡å‹åç§°åˆ—è¡¨ï¼Œå¦‚ ['FP NN', 'GNN GCN']
    - model_map (Dict[str, Dict]): ä» model_datasets.yaml åŠ è½½çš„æ¨¡å‹æ˜ å°„

    è¿”å›ï¼š
    - List[str]: æ‰€æœ‰æ¨¡å‹å…±åŒæ”¯æŒçš„æ•°æ®é›†åç§°åˆ—è¡¨
    """
    all_dataset_sets = []

    for model in model_list:
        try:
            model_name= model.split("_")[0]
            model_type = model.split("_")[1]
        except ValueError:
            continue  # å¿½ç•¥æ ¼å¼é”™è¯¯çš„æ¡ç›®

        datasets = model_map.get(model_name, {}).get(model_type)
        if datasets:
            all_dataset_sets.append(set(datasets))

    if not all_dataset_sets:
        return []

    common_datasets = set.intersection(*all_dataset_sets)
    return sorted(list(common_datasets))
def get_envs():
    env_root = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../environment.yaml')

    try:
        with open(env_root, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return {}

    if not isinstance(data, dict):
        print("æ–‡ä»¶å†…å®¹æ ¼å¼å¼‚å¸¸ï¼ŒæœŸæœ›é¡¶å±‚ä¸ºå­—å…¸")
        return {}

    # æœ€é«˜çº§é”®å’Œå¯¹åº”æ‰€æœ‰æ¬¡çº§é”®
    result = {}
    for top_key, sub_dict in data.items():
        if isinstance(sub_dict, dict):
            result[top_key] = list(sub_dict.keys())
        else:
            result[top_key] = []

    return result
     




# ----------- åˆå§‹åŒ– session_state -----------
if "selected_model_field" not in st.session_state:      # dataset_type
    st.session_state["selected_model_field"] = None
if "selected_model_workflow" not in st.session_state:   # workflow_type
    st.session_state["selected_model_workflow"] = None
if "selected_model_names" not in st.session_state:     # model_type
    st.session_state["selected_model_names"] = []
if "selected_datasets" not in st.session_state:
    st.session_state["selected_datasets"] = []
if "eval" not in st.session_state:
    st.session_state["eval"] = True
if "smiles_list" not in st.session_state:
    st.session_state["smiles_list"] = "random200"
if "smiles_input_mode" not in st.session_state:
    st.session_state["smiles_input_mode"] = "auto_eval"  # å¯é€‰: auto_eval, file_upload, manual_input
if "smiles_text_input" not in st.session_state:
    st.session_state["smiles_text_input"] = ""
if "smiles_file" not in st.session_state:
    st.session_state["smiles_file"] = None
if "smiles_eval_mode" not in st.session_state:
    st.session_state["smiles_eval_mode"] = "random"
if "smiles_eval_num" not in st.session_state:
    st.session_state["smiles_eval_num"] = 200
def on_workflow_change():
    st.session_state["selected_model_names"] = []
def get_top_level_keys():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    yaml_path = os.path.abspath(os.path.join(current_dir, '../environment.yaml'))

    with open(yaml_path, 'r', encoding='utf-8') as f:
        data = yaml.safe_load(f)

    if isinstance(data, dict):
        return list(data.keys())
    else:
        return []
def update(file, envname, model):
    current_dir = os.path.dirname(os.path.abspath(__file__))
    script_path = os.path.abspath(os.path.join(current_dir, '../env_utils.py'))
    env_md_path = os.path.abspath(os.path.join(current_dir, '../environment.yaml'))

    cmd = [sys.executable, script_path, "update", '-r', file, '-e', envname]

    try:
        subprocess.run(cmd, check=True, capture_output=True, text=True)
        st.success("æ›´æ–°æ‰§è¡ŒæˆåŠŸ")
    except subprocess.CalledProcessError as e:
        st.error(f"æ›´æ–°æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç ï¼š{e.returncode}")
        return False

    try:
        with open(env_md_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f) or {}

        if envname not in data:
            st.error(f"é”™è¯¯: environment.yaml é¡¶å±‚æ‰¾ä¸åˆ°ç¯å¢ƒå '{envname}'")
            return False

        data[envname][model] = file

        with open(env_md_path, 'w', encoding='utf-8') as f:
            yaml.safe_dump(data, f, allow_unicode=True, default_flow_style=False)

        return True
    except Exception as e:
        st.error(f"å†™å…¥ environment.yaml å¤±è´¥: {e}")
        return False


def create(model, file, envname, version):
    current_dir = os.path.dirname(os.path.abspath(__file__))
    script_path = os.path.abspath(os.path.join(current_dir, '../env_utils.py'))
    base_reqs = os.path.abspath(os.path.join(current_dir, '../requirements.txt'))
    env_md_path = os.path.abspath(os.path.join(current_dir, '../environment.yaml'))

    cmd = [sys.executable, script_path, 'create', '-r', base_reqs, '-a', file, '-e', envname, '-p', version]

    try:
        subprocess.run(cmd, check=True, capture_output=True, text=True)
        st.success("åˆ›å»ºæ‰§è¡ŒæˆåŠŸ")
    except subprocess.CalledProcessError as e:
        st.error(f"åˆ›å»ºæ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç ï¼š{e.returncode}")
        return False

    try:
        with open(env_md_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f) or {}

        if envname not in data or not isinstance(data[envname], dict):
            data[envname] = {}

        data[envname][model] = file
        data[envname]['molplat'] = "requirements.txt"

        with open(env_md_path, 'w', encoding='utf-8') as f:
            yaml.safe_dump(data, f, allow_unicode=True, default_flow_style=False)

        return True
    except Exception as e:
        st.error(f"å†™å…¥ environment.yaml å¤±è´¥: {e}")
        return False


def show_update_button(model, reqname):
    with st.expander("æ›´æ–°ç¯å¢ƒ"):
        keys = get_top_level_keys()
        if not keys:
            st.warning("environment.yaml æ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œæ— æ³•é€‰æ‹©ç¯å¢ƒåã€‚")
            return

        env_name = st.selectbox("é€‰æ‹©ç¯å¢ƒåå­—", keys)

        if st.button("Update"):
            st.text("â³ å¼€å§‹æ›´æ–°...")
            success = update(reqname, env_name, model)
            if success:
                st.success(f"âœ… Update æˆåŠŸï¼šmodel={model}, reqname={reqname}, envname={env_name}")
                st.text("å¦‚éœ€é‡æ–°æŸ¥çœ‹ç¯å¢ƒåˆ—è¡¨ï¼Œè¯·æ‰‹åŠ¨åˆ·æ–° 'ctrl r'")
            else:
                st.error("âŒ Update å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å‡ºä¿¡æ¯")


def show_create_button(model, reqname):
    with st.expander("åˆ›å»ºç¯å¢ƒ"):
        st.markdown("### åˆ›å»ºæ¨¡å‹é…ç½®")

        col3, col4 = st.columns(2)

        with col3:
            py_version = st.text_input("Python ç‰ˆæœ¬", value="3.11.8", max_chars=10)

        with col4:
            env_name = st.text_input("ç¯å¢ƒåå­—", max_chars=20)

        if st.button("Create"):
            if not py_version.strip() or not env_name.strip() or not model.strip() or not reqname.strip():
                st.error("è¯·å¡«å†™æ‰€æœ‰å­—æ®µï¼ŒåŒ…æ‹¬æ¨¡å‹åã€ä¾èµ–æ–‡ä»¶ã€Python ç‰ˆæœ¬å’Œç¯å¢ƒåï¼")
            else:
                st.text("åˆ›å»ºç¯å¢ƒä¸­â³")
                success = create(model, reqname, env_name, py_version)
                if success:
                    st.success(f"Create è°ƒç”¨æˆåŠŸï¼Œç¯å¢ƒå={env_name}, Pythonç‰ˆæœ¬={py_version}")
                    st.text("åˆ›å»ºæ–°ç¯å¢ƒæˆåŠŸï¼Œä½¿ç”¨æ–°ç¯å¢ƒï¼Œè¯·å…³é—­é‡å¯å¹³å°ï¼Œè¾“å…¥æ–°ç¯å¢ƒå")
                else:
                    st.error("åˆ›å»ºç¯å¢ƒå¤±è´¥ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹é”™è¯¯ä¿¡æ¯ã€‚")

def on_select_change():
    # é€‰æ¡†æ”¹å˜æ—¶ï¼Œå¦‚æœé€‰æ‹©â€œè‡ªå®šä¹‰è¾“å…¥â€ï¼Œä¿æŒfinal_model_typeä¸å˜ç­‰å¾…è¾“å…¥æ¡†è¾“å…¥
    # å¦åˆ™æ›´æ–°final_model_typeï¼Œå¹¶æ ‡è®°åˆ—è¡¨éœ€åˆ·æ–°
    selected = st.session_state["model_type_select"]
    if selected != "è‡ªå®šä¹‰è¾“å…¥":
        if st.session_state.get("final_model_type", "") != selected:
            st.session_state["final_model_type"] = selected
            st.session_state["model_list_changed"] = True

def on_custom_input_change():
    # è‡ªå®šä¹‰è¾“å…¥æ¡†æ”¹å˜æ—¶ï¼Œæ›´æ–°final_model_typeå¹¶æ ‡è®°åˆ·æ–°
    text = st.session_state.get("custom_model_input", "").strip()
    if st.session_state.get("final_model_type", "") != text:
        st.session_state["final_model_type"] = text
        st.session_state["model_list_changed"] = True

# é¡¶éƒ¨æŒ‰é’®
if "final_model_type" not in st.session_state:
    st.session_state["final_model_type"] = ""
if "uploaded_model_zip" not in st.session_state:
    st.session_state["uploaded_model_zip"] = None
if "uploaded_model_config" not in st.session_state:
    st.session_state["uploaded_model_config"] = None
if "uploaded_data_zip" not in st.session_state:
    st.session_state["uploaded_data_zip"] = None
if "uploaded_data_config" not in st.session_state:
    st.session_state["uploaded_data_config"] = None
if "show_model_input" not in st.session_state:
    st.session_state["show_model_input"] = False
if "model_list_changed" not in st.session_state:
    st.session_state["model_list_changed"] = True

# ----------- å±•å¼€æŒ‰é’® -----------
def repair_environment_record():
    try:
        # è·å–å½“å‰ç³»ç»Ÿä¸­æ‰€æœ‰condaç¯å¢ƒ
        conda_envs = get_conda_environments()
        
        # è¯»å–environment.yamlæ–‡ä»¶
        current_dir = os.path.dirname(os.path.abspath(__file__))
        env_md_path = os.path.abspath(os.path.join(current_dir, '../environment.yaml'))
        
        with open(env_md_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f) or {}
        
        # æ£€æŸ¥å¹¶ç§»é™¤ä¸å­˜åœ¨äºç³»ç»Ÿçš„ç¯å¢ƒ
        original_count = len(data)
        keys_to_remove = [env for env in data if env not in conda_envs]
        keys_to_keep = [env for env in data if env not in keys_to_remove]
        for env in keys_to_remove:
            del data[env]
        
        # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
        with open(env_md_path, 'w', encoding='utf-8') as f:
            yaml.safe_dump(data, f, allow_unicode=True, default_flow_style=False)
        
        return True, len(keys_to_remove), [keys_to_remove,keys_to_keep]
    except Exception as e:
        st.error(f"ä¿®å¤å¤±è´¥: {e}")
        return False, 0, []

# è·å–ç³»ç»Ÿä¸­æ‰€æœ‰condaç¯å¢ƒ
def get_conda_environments():
    try:
        # ä½¿ç”¨condaå‘½ä»¤è·å–ç¯å¢ƒåˆ—è¡¨
        result = subprocess.run(
            ['conda', 'env', 'list', '--json'],
            capture_output=True,
            text=True,
            check=True
        )
        
        # è§£æJSONè¾“å‡º
        env_data = json.loads(result.stdout)
        envs = env_data.get('envs', [])
        
        # æå–ç¯å¢ƒåç§°ï¼ˆè·¯å¾„çš„æœ€åéƒ¨åˆ†ï¼‰
        env_names = set()
        for env_path in envs:
            # åŸºæœ¬ç¯å¢ƒé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ªï¼Œåç§°ä¸º"base"
            if env_path == env_data.get('root_prefix'):
                env_names.add('base')
            else:
                env_name = os.path.basename(env_path)
                env_names.add(env_name)
        
        return env_names
    except Exception as e:
        st.error(f"è·å–condaç¯å¢ƒå¤±è´¥: {e}")
        return set()
    
close_tab_js = """
<script>
    window.close();
</script>
"""
exit_col_space, exit_col_btn = st.columns([9, 1])
with exit_col_btn:
    if st.button("âŒé€€å‡º"):
        st.warning("ç¨‹åºå³å°†å…³é—­...")
        st.components.v1.html(close_tab_js)
        os._exit(0)


col1, col2 = st.columns([10, 2])
with col1:
    envs = get_envs()

    # é€šè¿‡ HTML å’Œ CSS æ§åˆ¶æ ‡é¢˜å­—ä½“å¤§å°
    st.markdown("""
        <style>
        .small-title {
            font-size: 20px;
            font-weight: bold;
        }
        .env-item {
            margin-bottom: 8px;
            font-size: 14px;
        }
        </style>
    """, unsafe_allow_html=True)

    st.markdown("#### å¹³å°å·²åˆ›å»ºç¯å¢ƒåˆ—è¡¨ï¼Œå¯¹åº”è¯¥ç¯å¢ƒæ”¯æŒçš„ä¾èµ–æ¨¡å—å ï¼ˆå¦‚molplatä¸ºå¹³å°åŸºç¡€ä¾èµ–ï¼‰")
    
    # æ˜¾ç¤ºç¯å¢ƒå’Œæ¬¡çº§é”®
    for top_key, sub_keys in envs.items():
        sub_keys_str = ", ".join(sub_keys) if sub_keys else "(æ— ä¾èµ–å®‰è£…)"
        st.markdown(f'<div class="env-item"><b>{top_key}</b>: {sub_keys_str}</div>', unsafe_allow_html=True)


    current_env = os.environ.get('CONDA_DEFAULT_ENV', 'æœªæ£€æµ‹åˆ°å½“å‰ç¯å¢ƒ')

    st.markdown(f"<div style='font-size:14px;'>å½“å‰å¹³å°å·¥ä½œç¯å¢ƒï¼š{current_env}</div>", unsafe_allow_html=True)
    # æ·»åŠ ç¯å¢ƒä¿®å¤æŒ‰é’®
    st.markdown("---")
    with st.expander("ğŸ”§ ä¿®å¤ç¯å¢ƒè®°å½•", expanded=False):
        st.markdown("**æ‰«æå¹¶ç§»é™¤ç³»ç»Ÿä¸­å·²ä¸å­˜åœ¨çš„ç¯å¢ƒè®°å½•**")
        st.warning("æ­¤æ“ä½œå°†æ›´æ–° environment.yaml æ–‡ä»¶ï¼Œç§»é™¤æ‰€æœ‰ä¸å­˜åœ¨çš„ç¯å¢ƒè®°å½•")
        
        if st.button("æ‰«æå¹¶ä¿®å¤ç¯å¢ƒè®°å½•"):
            st.text("â³ æ­£åœ¨æ‰«æç¯å¢ƒ...")
            success, removed_count, return_list = repair_environment_record()
            if success:
                if removed_count > 0:
                    st.error(f"å‘ç° {removed_count} ä¸ªä¸å­˜åœ¨ç¯å¢ƒè®°å½•:")
                    st.error(",".join(return_list[0]))
                    st.success("âœ…å·²ç§»é™¤æ— æ•ˆç¯å¢ƒ")
                    st.success(f"æœ‰æ•ˆç¯å¢ƒ:")
                    st.success(",".join(return_list[1]))
                    st.text("å¦‚éœ€æ›´æ–°ç¯å¢ƒåˆ—è¡¨ï¼Œè¯·æ‰‹åŠ¨åˆ·æ–° 'ctrl r'")
                else:
                    st.info("æœªæ£€æµ‹åˆ°å·²åˆ é™¤ç¯å¢ƒè®°å½•ï¼Œç¯å¢ƒåˆ—è¡¨æ­£å¸¸")
            else:
                st.error("âŒ ä¿®å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å‡ºä¿¡æ¯")

    st.write("")
    st.write("")

with col2:
    if st.button("â• æ·»åŠ æ•°æ®é›†ä¸æ¨¡å‹ï¼ˆç‚¹å‡»ä»¥è¿”å›ï¼‰"):
        st.session_state["show_model_input"] = not st.session_state["show_model_input"]

# ----------- å±•å¼€åŒºåŸŸ -----------
if st.session_state.get("show_model_input", True):

    st.markdown("#### ğŸ”§ è‡ªå®šä¹‰æ•°æ®é›†ç±»å‹ä¸æ¨¡å‹åŒ…ä¸Šä¼ ")
    st.markdown("** æ³¨æ„ï¼Œå¦‚æœæ¨¡å‹ä¾èµ–pythonåº“ï¼Œè¯·åœ¨ç»ˆç«¯è‡ªè¡Œå®‰è£…ä»¥é¿å…å†²çª")

    # ä¸Šä¼ è¯´æ˜æ–‡ä»¶å±•ç¤º
    if os.path.exists(UPLOAD_MODEL_README):
        with open(UPLOAD_MODEL_README, "r", encoding="utf-8") as f:
            model_readme_text = f.read()
        with st.expander("ğŸ“˜ æŸ¥çœ‹æ¨¡å‹ä¸Šä¼ è¯´æ˜ (MODEL_readme.md)"):
            render_scrollable_markdown(model_readme_text, height=600)

    if os.path.exists(UPLOAD_DATA_README):
        with open(UPLOAD_DATA_README, "r", encoding="utf-8") as f:
            data_readme_text = f.read()
        with st.expander("ğŸ“— æŸ¥çœ‹æ•°æ®ä¸Šä¼ è¯´æ˜ (DATASET_readme.md)"):
            render_scrollable_markdown(data_readme_text, height=600)

    # è·å–æ‰€æœ‰æ¨¡å‹ç±»å‹
    try:
        all_model_types = get_all_model_types()
    except Exception as e:
        st.warning(f"åŠ è½½æ•°æ®é›†ç±»å‹å¤±è´¥ï¼š{e}")
        all_model_types = []

    model_type_options = ["è‡ªå®šä¹‰è¾“å…¥"] + all_model_types

    # è®¡ç®—å½“å‰é€‰ä¸­indexï¼Œé»˜è®¤é€‰è‡ªå®šä¹‰è¾“å…¥
    if st.session_state["final_model_type"] in all_model_types:
        current_index = model_type_options.index(st.session_state["final_model_type"])
    else:
        current_index = 0

    selected_option = st.selectbox(
        "ä»å·²æœ‰æ•°æ®é›†ç±»å‹ä¸­é€‰æ‹©æˆ–ç›´æ¥è¾“å…¥æ–°ç±»å‹ï¼š",
        options=model_type_options,
        index=current_index,
        key="model_type_select",
        on_change=on_select_change,
    )

    if selected_option == "è‡ªå®šä¹‰è¾“å…¥":
        custom_input = st.text_input(
            "è¯·è¾“å…¥æ–°çš„æ•°æ®é›†ç±»å‹å¹¶å›è½¦",
            value=st.session_state.get("custom_model_input", ""),
            key="custom_model_input",
            on_change=on_custom_input_change,
        )
    else:
        if "custom_model_input" in st.session_state:
            del st.session_state["custom_model_input"]

    if selected_option != "è‡ªå®šä¹‰è¾“å…¥" and st.session_state.get("final_model_type"):

        if st.session_state["model_list_changed"]:
            # åªæœ‰éè‡ªå®šä¹‰è¾“å…¥ï¼Œä¸”åˆ—è¡¨æ”¹å˜æ—¶ï¼ŒåŠ è½½åˆ—è¡¨
            models_list, datasets_list = get_models_and_data(st.session_state["final_model_type"])
            st.session_state["models_list"] = models_list
            st.session_state["datasets_list"] = datasets_list
            st.session_state["model_list_changed"] = False

        datatype = get_data_type(st.session_state["final_model_type"])
        st.markdown(f"**ğŸ§¬ å¯¹åº”çš„æ•°æ®è¾“å…¥æ ¼å¼ï¼š** `{datatype}`")

        if st.session_state.get("models_list"):
            with st.expander("ğŸ“¦ å·²æœ‰æ¨¡å‹åˆ—è¡¨ (models_list)"):
                for model_name in st.session_state["models_list"]:
                    cols = st.columns([4, 1])
                    cols[0].markdown(f"- {model_name}")
                    if cols[1].button("ğŸ—‘ï¸ åˆ é™¤", key=f"del_{model_name}"):
                        delete(st.session_state["final_model_type"], model_name)
                        st.session_state["model_list_changed"] = True

        if st.session_state.get("datasets_list"):
            with st.expander("ğŸ—‚ï¸ å·²æœ‰æ•°æ®é›†åˆ—è¡¨ (datasets_list)"):
                st.markdown("\n".join(f"- {item}" for item in st.session_state["datasets_list"]))
    final_model_type = st.session_state.final_model_type

    # ----------- ä¸Šä¼ æ–‡ä»¶åŒºåŸŸ -----------
    uploaded_zip = st.file_uploader(f"ğŸ“¦ ä¸Šä¼ æ¨¡å‹æ–‡ä»¶åŒ…ï¼ˆmodel.zipï¼‰ï¼Œè¿‡å¤§æ–‡ä»¶è¯·æ‰‹åŠ¨è§£å‹ç¼©å¹¶æ”¾å…¥molplat_form/dataset/data/ä½ é€‰æ‹©çš„æ¨¡å‹ç±»å‹ ç›®å½•ä¸‹ï¼ˆmolplat_form/dataset/data/{final_model_type}ï¼‰", type=["zip"])
    if uploaded_zip:
        st.session_state["uploaded_model_zip"] = uploaded_zip
        st.success(f"âœ… ä¸Šä¼ æ¨¡å‹åŒ…ï¼š{uploaded_zip.name}")

    uploaded_model_config = st.file_uploader("ğŸ“„ ä¸Šä¼ æ¨¡å‹é…ç½®æ–‡ä»¶ï¼ˆmodel_config.yamlï¼‰", type=["yaml"])
    if uploaded_model_config:
        st.session_state["uploaded_model_config"] = uploaded_model_config
        st.success(f"âœ… ä¸Šä¼ æ¨¡å‹é…ç½®ï¼š{uploaded_model_config.name}")
        
    uploaded_data_config = st.file_uploader("ğŸ“„ ä¸Šä¼ æ•°æ®é…ç½®æ–‡ä»¶ï¼ˆdata_config.yamlï¼‰", type=["yaml"])
    if uploaded_data_config:
        st.session_state["uploaded_data_config"] = uploaded_data_config
        st.success(f"âœ… ä¸Šä¼ æ•°æ®é…ç½®ï¼š{uploaded_data_config.name}")

    uploaded_data_zip = st.file_uploader(f"ğŸ—‚ï¸ ä¸Šä¼ æ•°æ®æ–‡ä»¶åŒ…ï¼ˆdata.zipï¼‰ï¼Œè¿‡å¤§æ–‡ä»¶è¯·æ‰‹åŠ¨è§£å‹ç¼©å¹¶æ”¾å…¥molplat_form/models/ä½ é€‰æ‹©çš„æ¨¡å‹ç±»å‹ ç›®å½•ä¸‹ ï¼ˆmolplat_form/models/{final_model_type}ï¼‰", type=["zip"])
    if uploaded_data_zip:
        st.session_state["uploaded_data_zip"] = uploaded_data_zip
        st.success(f"âœ… ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼š{uploaded_data_zip.name}")

    # ----------- æ˜¾ç¤ºç”¨æˆ·è¾“å…¥çŠ¶æ€ -----------
    if final_model_type:
        st.success(f"ğŸ¯ é€‰æ‹©/è¾“å…¥çš„æ•°æ®é›†ç±»å‹ï¼š`{final_model_type}`")
    if st.button("ğŸš€ æäº¤å¹¶å¤„ç†"):
        if st.session_state.model_type_select == "è‡ªå®šä¹‰è¾“å…¥" and not st.session_state.final_model_type.strip():
            st.warning("âš ï¸ è¯·è¾“å…¥è‡ªå®šä¹‰æ•°æ®é›†ç±»å‹åç§°åå†æäº¤ã€‚")
        else:# è·å–ä¸Šä¼ çš„æ–‡ä»¶
            model_zip = st.session_state.get("uploaded_model_zip")
            model_config = st.session_state.get("uploaded_model_config")
            data_zip = st.session_state.get("uploaded_data_zip")
            data_config = st.session_state.get("uploaded_data_config")

            # æ£€æŸ¥æ¨¡å‹ç»„æ˜¯å¦å®Œæ•´
            model_ready = (model_zip is not None) and (model_config is not None)
            # æ£€æŸ¥æ•°æ®ç»„æ˜¯å¦å®Œæ•´
            data_ready = (data_zip is not None) and (data_config is not None)
            all_configs = (model_config is not None ) and (data_config is not None)

            # æƒ…å†µ1ï¼šæ¨¡å‹ç»„å®Œæ•´ï¼Œdata_zip å¯ä»¥ç¼ºå¤±ï¼ˆä½† data_config å¿…é¡»ä¼ ï¼‰
            condition1 = model_ready and (data_config is not None)
            # æƒ…å†µ2ï¼šæ•°æ®ç»„å®Œæ•´ï¼Œæ¨¡å‹ç»„å¯ä»¥å®Œå…¨ç¼ºå¤±
            condition2 = data_ready and (not model_ready)
            condition3 = model_ready and data_ready

            if condition1 or condition2 or condition3 or all_configs:
                # âœ… æ»¡è¶³æ¡ä»¶ï¼Œè°ƒç”¨ process
                result = process(
                    final_model_type,
                    model_zip,
                    model_config,
                    data_zip,
                    data_config
                )
                
                if result is True:
                    st.success("âœ… æ¨¡å‹å¯¼å…¥å®Œæˆï¼")
                else:
                    st.error(result)
            else:
                # âŒ ä¸æ»¡è¶³æ¡ä»¶ï¼Œæç¤ºé”™è¯¯
                missing = []
                if not model_ready:
                    missing.append("æ¨¡å‹ç»„ï¼ˆéœ€åŒæ—¶ä¸Šä¼  model_zip å’Œ model_configï¼‰")
                if data_config is None:
                    missing.append("data_configï¼ˆå¿…é¡»ä¸Šä¼ ï¼‰")
                if not data_ready and (data_zip is not None or data_config is not None):
                    missing.append("æ•°æ®ç»„ä¸å®Œæ•´ï¼ˆéœ€åŒæ—¶ä¸Šä¼  data_zip å’Œ data_configï¼‰")

                st.error(f"""
                âš ï¸ **æäº¤å¤±è´¥ï¼**  
                è¯·ç¡®ä¿ç¬¦åˆä»¥ä¸‹æ¡ä»¶ä¹‹ä¸€ï¼š
                - **æƒ…å†µ1**ï¼šå®Œæ•´ä¸Šä¼ æ¨¡å‹ç»„ï¼ˆ`model_zip` + `model_config`ï¼‰ï¼Œå¹¶è‡³å°‘ä¸Šä¼  `data_config`ï¼ˆ`data_zip` å¯é€‰ï¼‰ï¼Œ**æˆ–**  
                - **æƒ…å†µ2**ï¼šå®Œæ•´ä¸Šä¼ æ•°æ®ç»„ï¼ˆ`data_zip` + `data_config`ï¼‰ï¼Œä¸ä¸Šä¼ æ¨¡å‹ç»„ï¼Œ**æˆ–** 
                - **æƒ…å†µ3**: å…¨éƒ¨å®Œæ•´ä¸Šä¼  ï¼Œ**æˆ–** 
                - **æƒ…å†µ4**: ä¸Šä¼ config å¹¶å°†å…¶ä½™æ–‡ä»¶æ”¾å…¥å¯¹åº”æ–‡ä»¶å¤¹ä¸‹


                """)
else:
    # ----------- å½“ model_field å˜åŒ–æ—¶ï¼Œé‡ç½®æ‰€æœ‰ç›¸å…³é€‰æ‹© -----------
    def on_model_field_change():
        st.session_state["selected_model_workflows"] = []  # æ”¹ä¸ºåˆ—è¡¨
        st.session_state["selected_model_names"] = []
        st.session_state["selected_datasets"] = []
        st.session_state["selected_tasks"] = []
        st.session_state["_last_selected_dataset"] = None
        
    model_field_options = get_all_model_types()
    st.markdown("### è¯·é€‰æ‹©å¹³å°é¢„æµ‹æ–¹æ³•")
    st.selectbox(
        "æ¨¡å‹æ‰€å±æ•°æ®é›†ç±»å‹",
        options=model_field_options,
        key="selected_model_field",
        on_change=on_model_field_change
    )    
    
    # ----------- ä» model_dataset_map.yaml è·å–æ•°æ®é›†åˆ—è¡¨ -----------
    @st.cache_data
    def load_model_map(modelfield, path=MODEL_PATH):
        new_path = os.path.join(path, 'models.yaml')
        with open(new_path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)

        # è¿”å›æ•°æ®ç»“æ„æ”¹ä¸º {å·¥ä½œæµ: {æ¨¡å‹åç§°: é…ç½®}}
        return data.get(modelfield, {}).get("models", {})

    model_field = st.session_state["selected_model_field"]
    if model_field:
        model_map = load_model_map(model_field)
        workflows = list(model_map.keys())  # è·å–æ‰€æœ‰å·¥ä½œæµ
        
        # å°†å·¥ä½œæµé€‰æ‹©æ”¹ä¸ºå¤šé€‰æ¡†
        st.multiselect(
            "æ¨¡å‹å·¥ä½œæµï¼ˆå¯å¤šé€‰ï¼‰",
            options=workflows,
            key="selected_model_workflows",  # æ”¹ä¸ºå¤æ•°å½¢å¼
            on_change=lambda: st.session_state.update({"selected_model_names": []})  # å·¥ä½œæµå˜åŒ–æ—¶é‡ç½®æ¨¡å‹é€‰æ‹©
        )
        
        # æ ¹æ®é€‰æ‹©çš„å¤šä¸ªå·¥ä½œæµåŠ è½½æ‰€æœ‰æ¨¡å‹
        if st.session_state["selected_model_workflows"]:
            all_model_options = []
            
            # éå†æ¯ä¸ªé€‰ä¸­çš„å·¥ä½œæµ
            for workflow in st.session_state["selected_model_workflows"]:
                # è·å–è¯¥å·¥ä½œæµä¸‹çš„æ‰€æœ‰æ¨¡å‹
                for model_key in model_map[workflow].keys():
                    full_model = f"{workflow}_{model_key}"
                    all_model_options.append(full_model)
            
            # å»é‡å¹¶æ’åº
            all_model_options = sorted(set(all_model_options))
            model_options_with_all = all_model_options + ["all"]
            
            st.multiselect(
                "æ¨¡å‹åç§°ï¼ˆå¯å¤šé€‰ï¼‰",
                options=model_options_with_all,
                key="selected_model_names"
            )

    # ä½¿ç”¨ selected_model_names æ›¿ä»£åŸæ¥çš„ selected_models
    if "all" in st.session_state["selected_model_names"]:
        model = all_model_options  # ä½¿ç”¨ä¹‹å‰æ”¶é›†çš„æ‰€æœ‰æ¨¡å‹
    else:
        model = st.session_state["selected_model_names"]
        
    # ç¯å¢ƒç®¡ç†éƒ¨åˆ†ï¼šä¸ºæ¯ä¸ªé€‰ä¸­çš„å·¥ä½œæµåˆ†åˆ«æ˜¾ç¤º
    if model and st.session_state["selected_model_workflows"]:
        # éå†æ¯ä¸ªé€‰ä¸­çš„å·¥ä½œæµ
        for model_workflow in st.session_state["selected_model_workflows"]:
            
            readname = f"{model_workflow}_readme.md"
            outputname = f"{model_workflow}_output.py"
            dataname = f"{model_workflow}_data.py"
            modelname = f"{model_workflow}_model.py"
            reqname =  f"{model_workflow}_requirements.txt"
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            READMEFILE_PATH = os.path.join(project_root, 'models', model_field, readname)
            OUTPUTFILE_PATH = os.path.join(project_root, 'models', model_field, model_workflow, outputname)
            DATAFILE_PATH = os.path.join(project_root, 'models', model_field, model_workflow, dataname)
            MODELFILE_PATH = os.path.join(project_root, 'models', model_field, model_workflow, modelname)
            REQ_PATH = os.path.join(project_root, 'models', model_field, reqname)
            
            st.markdown("#### ç¯å¢ƒç®¡ç†åŠŸèƒ½")
            st.markdown("**æœ¬åŠŸèƒ½é»˜è®¤ä½¿ç”¨æ¨¡å‹å·¥ä½œæµrequirements.txtæ–‡ä»¶ï¼Œä½¿ç”¨ä¸€å»ºåŒ–åŠŸèƒ½å‰ï¼Œè¯·æŸ¥é˜…README.mdï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºæ¨¡å‹å·¥ä½œæµæ‰€éœ€å…¨éƒ¨ä¾èµ–ï¼Œéƒ¨åˆ†ä¾èµ–å¯èƒ½é¡»æŒ‰æŒ‡å¼•æ‰‹åŠ¨å®‰è£…**")
            
            # æ˜¾ç¤ºæ–‡ä»¶é€‰æ‹©å™¨
            show_file_selector(f"{model_workflow}: requirements.txt ", REQ_PATH, is_text=True)
            show_file_selector(f"{model_workflow}: README.md", READMEFILE_PATH, is_markdown=True)
            
            # æ˜¾ç¤ºç¯å¢ƒç®¡ç†æŒ‰é’®
            col1, col2 = st.columns(2)
            with col1:
                show_update_button(model_workflow, REQ_PATH)
            with col2:
                show_create_button(model_workflow, REQ_PATH)
            
            st.markdown("**æ¨¡å‹å·¥ä½œæµæ ¸å¿ƒæ–‡ä»¶**")
            show_file_selector(f"{model_workflow}: Output Script", OUTPUTFILE_PATH)
            show_file_selector(f"{model_workflow}: Data Script", DATAFILE_PATH)
            show_file_selector(f"{model_workflow}: Model Script", MODELFILE_PATH)
            
            st.markdown("---")  # æ·»åŠ åˆ†éš”çº¿

    #--------datasets åªæœ‰åœ¨ model å‡ºç°çš„æ—¶å€™å†å‡ºç°
    def on_dataset_change():
        st.session_state["selected_tasks"] = []  # é‡ç½®ä»»åŠ¡é€‰æ‹©
        st.session_state["_last_selected_dataset"] = None  # æ¸…é™¤ä¸Šæ¬¡ä»»åŠ¡çš„ç¼“å­˜æ ‡è®°

    if "selected_datasets" not in st.session_state:
        st.session_state["selected_datasets"] = []

    if model:
        available_datasets = get_datasets_for_model(model, model_map)
        dataset_options_with_all = available_datasets + ["all"]
        st.markdown("### è¯·é€‰æ‹©é¢„æµ‹å¯¹è±¡")
        st.multiselect(
            "æ•°æ®é›†åç§° (name)",
            options=dataset_options_with_all,
            key="selected_datasets",
            on_change=on_dataset_change
        )

        if "all" in st.session_state["selected_datasets"]:
            name = available_datasets
        else:
            name = st.session_state["selected_datasets"]

    # ----------- ä»»åŠ¡é€‰æ‹©ï¼ˆtarget_listï¼‰-----------
    if "selected_tasks" not in st.session_state:
        st.session_state["selected_tasks"] = []

    if "name" in locals() and name:
        if len(name) > 1:
            st.markdown("**ä»»åŠ¡åç§° (target_list):** all")
            target_list = "all"
        else:
            dataset_name = name[0]

            try:
                utils = CheckUtils(st.session_state["selected_model_field"])
                available_tasks = utils.get_datasets_measure_names(dataset_name)
                task_options_with_all = available_tasks + ["all"]

                # å¦‚æœæ¢äº†æ•°æ®é›†ï¼Œé‡ç½®ä»»åŠ¡é€‰æ‹©
                if st.session_state.get("_last_selected_dataset") != dataset_name:
                    st.session_state["selected_tasks"] = []
                    st.session_state["_last_selected_dataset"] = dataset_name

                st.multiselect(
                    "ä»»åŠ¡åç§° (target_list)",
                    options=task_options_with_all,
                    key="selected_tasks"
                )

                if "all" in st.session_state["selected_tasks"]:
                    target_list = available_tasks
                else:
                    target_list = st.session_state["selected_tasks"]

            except Exception as e:
                st.warning(f"æ— æ³•è·å–ä»»åŠ¡åˆ—è¡¨ï¼š{e}")
                target_list = "all"


    # ----------- evaluation è¾“å…¥æ¡† -----------
    if "eval" not in st.session_state:
        st.session_state["eval"] = True
    eval = st.checkbox("æ˜¯å¦è¯„ä¼°æ¨¡å‹å¹¶ç»˜å›¾ (å¿…é¡»å…ˆä¸Šä¼ æ•°æ®)", key="eval")

    # ----------- smiles_list è¾“å…¥æ¡† -----------
    if "smiles_list" not in st.session_state:
        st.session_state["smiles_list"] = "random200"
    st.markdown("### é€‰æ‹©æ•°æ®è¾“å…¥æ–¹å¼")
    mode_display_to_internal = {
        "è‡ªåŠ¨è¯„ä¼°(å¿…é¡»å…ˆä¸Šä¼ å¯¹åº”æ•°æ®)": "auto_eval",
        "ä¸Šä¼ æ–‡ä»¶": "file_upload",
        "æ‰‹åŠ¨è¾“å…¥": "manual_input"
    }
    mode_internal_to_display = {v: k for k, v in mode_display_to_internal.items()}

    # æ§ä»¶ï¼šé€‰æ‹©æ¨¡å¼ï¼ˆåªè¯»ï¼Œä¸ç›´æ¥æ”¹ session_stateï¼‰
    selected_mode_display = st.radio(
        "è¯·é€‰æ‹©ä¸€ç§æ–¹å¼",
        options=list(mode_display_to_internal.keys()),
        index=list(mode_display_to_internal.values()).index(st.session_state["smiles_input_mode"])
    )

    # å°† radio æ§ä»¶ç»“æœå†™å…¥ session
    if mode_display_to_internal[selected_mode_display] != st.session_state["smiles_input_mode"]:
        st.session_state["smiles_input_mode"] = mode_display_to_internal[selected_mode_display]
        st.rerun()

    # ä¸‰ç§æ¨¡å¼åˆ†åˆ«å¤„ç†
    mode = st.session_state["smiles_input_mode"]

    if mode == "auto_eval":
        smiles_eval_mode = st.selectbox(
            "é€‰æ‹©è¯„ä¼°æ¨¡å¼",
            ["random", "all"],
            index=["random", "all"].index(st.session_state["smiles_eval_mode"])
        )

        if smiles_eval_mode != st.session_state["smiles_eval_mode"]:
            st.session_state["smiles_eval_mode"] = smiles_eval_mode
            st.rerun()

        if st.session_state["smiles_eval_mode"] == "random":
            smiles_eval_num = st.number_input("è¯·è¾“å…¥è¦éšæœºé€‰æ‹©çš„æ•°é‡", min_value=1, value=st.session_state["smiles_eval_num"], step=200)
            if smiles_eval_num != st.session_state["smiles_eval_num"]:
                st.session_state["smiles_eval_num"] = smiles_eval_num
                st.session_state["smiles_list"] = f"random{smiles_eval_num}"
            else:
                st.session_state["smiles_list"] = f"random{st.session_state['smiles_eval_num']}"
        else:
            st.session_state["smiles_list"] = "all"

    elif mode == "file_upload":
        uploaded_file = st.file_uploader("ä¸Šä¼ åŒ…å« æ•°æ® çš„ .txt æˆ– .csv æ–‡ä»¶", type=["txt", "csv"])
        if uploaded_file is not None:
            st.session_state["smiles_file"] = uploaded_file
            if uploaded_file.name.endswith(".txt"):
                content = uploaded_file.read().decode("utf-8")
                lines = [line.strip() for line in content.splitlines() if line.strip()]
                st.session_state["smiles_list"] = lines
            elif uploaded_file.name.endswith(".csv"):
                df = pd.read_csv(uploaded_file)
                col = st.selectbox("é€‰æ‹©æ•°æ®æ‰€åœ¨åˆ—", df.columns)
                smiles = df[col].dropna().astype(str).tolist()
                st.session_state["smiles_list"] = smiles

    elif mode == "manual_input":
        text = st.text_area("è¯·è¾“å…¥é€—å·åˆ†éš”çš„æ•°æ®", value=st.session_state["smiles_text_input"])
        if text != st.session_state["smiles_text_input"]:
            st.session_state["smiles_text_input"] = text
            smiles = [s.strip() for s in text.split(",") if s.strip()]
            st.session_state["smiles_list"] = smiles


    # ----------- è¿è¡ŒæŒ‰é’® -----------
    if st.button("è¿è¡Œæ¨¡å‹é…ç½®å¹¶ä¿å­˜é…ç½®æ–‡ä»¶"):
        fields_to_convert = ["model", "name", "target_list"]
        config = load_config()
        config["user_argument"] = st.session_state["selected_model_field"]
        config["model"] = model
        config["name"] = name
        config["target_list"] = target_list
        config["eval"] = st.session_state["eval"]
        smiles_val = st.session_state.get("smiles_list", "")
        if isinstance(smiles_val, list):
            config["smiles_list"] = ",".join(smiles_val)
        else:
            config["smiles_list"] = smiles_val
        config = list_to_csv_fields(config, fields_to_convert)

        save_config(config)
        st.success("é…ç½®å·²ä¿å­˜ï¼")

        try:
            # è¿è¡Œå­è¿›ç¨‹å¹¶æ•è·è¾“å‡º
            result = subprocess.run(
                ["python", RUN_SCRIPT_PATH],
                capture_output=True,  # æ•è·æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯è¾“å‡º
                text=True,            # ä»¥æ–‡æœ¬å½¢å¼è¿”å›
                encoding='utf-8',     # æŒ‡å®šç¼–ç 
                check=True            # å¦‚æœè¿”å›éé›¶çŠ¶æ€ç åˆ™å¼•å‘å¼‚å¸¸
            )
            st.success("âœ… æ¨¡å‹è¿è¡Œå®Œæˆï¼")
            
            # å¤„ç†æˆåŠŸè¿è¡Œåçš„é€»è¾‘...
            result_path = os.path.join(project_root,'results','results')
            run_id,latest_run_path = get_latest_run_folder(result_path)
            history_record = {
                "timestamp": datetime.now().isoformat(),
                "run_id": run_id,
                "model_argument": config["user_argument"],
                "model": config["model"],
                "dataset": config["name"],
                "task": config["target_list"],
                "data": config["smiles_list"],
                "eval": config["eval"]
            }
            history_list = []
            if os.path.exists(HISTORY_PATH):
                with open(HISTORY_PATH, "r", encoding="utf-8") as f:
                    history_list = json.load(f)
            history_list.insert(0, history_record)
            with open(HISTORY_PATH, "w", encoding="utf-8") as f:
                json.dump(history_list, f, indent=2, ensure_ascii=False)

            if latest_run_path:
                config_path = os.path.join(latest_run_path, "config.json")
                with open(config_path, "w", encoding="utf-8") as f:
                    json.dump(config, f, indent=2, ensure_ascii=False)
                if config['eval']:
                    plot_dir = os.path.join(latest_run_path, "plots")
                    st.markdown("## ğŸ–¼ï¸ æ¨¡å‹åˆ†æå›¾ (plots)")
                    display_images_recursively(plot_dir)

                st.markdown("## ğŸ“Š æ¨¡å‹ç»“æœè¡¨æ ¼ (CSVs)")
                display_csv_tables(latest_run_path)
            else:
                st.warning("æœªæ‰¾åˆ°ä»»ä½• runXX ç»“æœç›®å½•ã€‚")

        except subprocess.CalledProcessError as e:
            # å½“å‘½ä»¤è¿”å›éé›¶çŠ¶æ€ç æ—¶ï¼Œæ˜¾ç¤ºè¯¦ç»†é”™è¯¯
            error_msg = f"âŒ æ¨¡å‹è¿è¡Œå¤±è´¥ (è¿”å›ç : {e.returncode})!\n\n" 
            error_msg += "=== é”™è¯¯è¯¦æƒ… ===\n"
            error_msg += e.stderr + "\n"
            error_msg += "è¯·æ£€æŸ¥æ¨¡å‹ç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½® ï¼ˆmodel: README.mdï¼‰"
            st.error(error_msg)
            
            # åœ¨ç»ˆç«¯æ‰“å°å®Œæ•´é”™è¯¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            print("="*80)
            print(f"å­è¿›ç¨‹è¯¦ç»†é”™è¯¯ä¿¡æ¯ (è¿”å›ç  {e.returncode}):")
            print(e.stderr)
            print("="*80)
            
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸
            st.error(f"è¿è¡Œå‡ºé”™ï¼š{e}")
            print(f"è¿è¡Œå‡ºé”™ï¼š{e}")

if os.path.exists(HISTORY_PATH):
    with open(HISTORY_PATH, "r", encoding="utf-8") as f:
        history_list = json.load(f)

    if history_list:
        st.markdown("---")
        st.markdown("### ğŸ“‚ å†å²è¿è¡Œè®°å½•ï¼ˆå¯ä»¥åœ¨results/resultsä¸‹æŸ¥çœ‹æ¯ä¸€æ¬¡çš„å…·ä½“ç»“æœï¼‰")
        
        # æ·»åŠ ä¿®å¤å†å²è®°å½•é€‰é¡¹
        st.markdown("#### ğŸ”§ ä¿®å¤å†å²è®°å½•")
        col_repair1, col_repair2 , col_repair3= st.columns(3)
        
                # ä¿®æ”¹ç§»é™¤æ— æ•ˆè®°å½•åŠŸèƒ½
        with col_repair1:
            if st.button("ç§»é™¤æ— æ•ˆè®°å½•", key="remove_invalid"):
                # æ‰«æç»“æœç›®å½•è·å–æœ‰æ•ˆrun_id
                valid_run_ids = set()
                results_dir = os.path.join(project_root, 'results', 'results')
                if os.path.exists(results_dir):
                    for run_id in os.listdir(results_dir):
                        run_path = os.path.join(results_dir, run_id)
                        if os.path.isdir(run_path):
                            # æ£€æŸ¥ç»“æœç›®å½•æ˜¯å¦åŒ…å«é…ç½®æ–‡ä»¶
                            if os.path.exists(os.path.join(run_path, 'config.json')):
                                valid_run_ids.add(run_id)
                
                # è¿‡æ»¤å†å²è®°å½•ï¼Œåªä¿ç•™æœ‰æ•ˆè®°å½•
                updated_history = [r for r in history_list if r['run_id'] in valid_run_ids]
                
                # ä¿å­˜æ›´æ–°åçš„å†å²è®°å½•
                with open(HISTORY_PATH, "w", encoding="utf-8") as f:
                    json.dump(updated_history, f, indent=2, ensure_ascii=False)
                
                st.success(f"å·²ç§»é™¤ {len(history_list) - len(updated_history)} æ¡æ— æ•ˆè®°å½•ï¼")
                st.rerun()
                # æ–°å¢ç¬¬ä¸‰åˆ—ï¼šæ¸…é™¤å…¨éƒ¨å†å²è®°å½•

        with col_repair2:
            if st.button("æ·»åŠ ç¼ºå¤±è®°å½•", key="add_missing"):
                # æ‰«æç»“æœç›®å½•è·å–æ‰€æœ‰run_id
                results_dir = os.path.join(project_root, 'results', 'results')
                existing_run_ids = set(r['run_id'] for r in history_list)
                new_records = []
                
                if os.path.exists(results_dir):
                    for run_id in os.listdir(results_dir):
                        if run_id in existing_run_ids:
                            continue
                            
                        run_path = os.path.join(results_dir, run_id)
                        if not os.path.isdir(run_path):
                            continue
                            
                        # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                        config_path = os.path.join(run_path, 'config.json')
                        if os.path.exists(config_path):
                            try:
                                with open(config_path, 'r', encoding='utf-8') as config_file:
                                    run_config = json.load(config_file)
                                    
                                # è·å–ç›®å½•åˆ›å»ºæ—¶é—´ä½œä¸ºæ—¶é—´æˆ³
                                ctime = os.path.getctime(run_path)
                                timestamp = datetime.fromtimestamp(ctime).isoformat()
                                
                                # åˆ›å»ºè®°å½• - ä½¿ç”¨config.jsonä¸­çš„å‚æ•°
                                new_records.append({
                                    'timestamp': timestamp,
                                    'run_id': run_id,
                                    'model_argument': run_config.get("user_argument", "æœªçŸ¥"),
                                    'model': run_config.get("model", "æœªçŸ¥"),
                                    'dataset': run_config.get("name", "æœªçŸ¥"),
                                    'task': run_config.get("target_list", "æœªçŸ¥"),
                                    'data': run_config.get("smiles_list", "æœªçŸ¥"),
                                    'eval': run_config.get("eval", True)
                                })
                            except Exception as e:
                                st.warning(f"æ— æ³•è¯»å– {run_id} çš„é…ç½®æ–‡ä»¶: {e}")
                        else:
                            # å¦‚æœæ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œåˆ›å»ºåŸºç¡€è®°å½•
                            ctime = os.path.getctime(run_path)
                            timestamp = datetime.fromtimestamp(ctime).isoformat()
                            new_records.append({
                                'timestamp': timestamp,
                                'run_id': run_id,
                                'model_argument': 'æœªçŸ¥',
                                'model': 'æœªçŸ¥',
                                'dataset': 'æœªçŸ¥',
                                'task': 'æœªçŸ¥',
                                'data': 'æœªçŸ¥',
                                'eval': True
                            })
                
                if new_records:
                    # æ·»åŠ æ–°è®°å½•åˆ°å†å²è®°å½•
                    updated_history = history_list + new_records
                    
                    # ä¿å­˜æ›´æ–°åçš„å†å²è®°å½•
                    with open(HISTORY_PATH, "w", encoding="utf-8") as f:
                        json.dump(updated_history, f, indent=2, ensure_ascii=False)
                    
                    st.success(f"å·²æ·»åŠ  {len(new_records)} æ¡ç¼ºå¤±è®°å½•ï¼")
                    st.rerun()
                else:
                    st.info("æœªå‘ç°ç¼ºå¤±è®°å½•")

        with col_repair3:
            if st.button("æ¸…é™¤å…¨éƒ¨å†å²è®°å½•", key="clear_all_history", 
                         help="âš ï¸ æ¸…é™¤æ‰€æœ‰å†å²è®°å½•ï¼ˆä¸ä¼šåˆ é™¤ç»“æœæ–‡ä»¶ï¼‰"):
                if st.session_state.get("confirm_clear_all", False):
                    # åˆ é™¤å†å²è®°å½•æ–‡ä»¶
                    try:
                        os.remove(HISTORY_PATH)
                        st.success("å·²æ¸…é™¤å…¨éƒ¨å†å²è®°å½•ï¼")
                        st.session_state.pop("confirm_clear_all", None)
                        st.rerun()
                    except Exception as e:
                        st.error(f"æ¸…é™¤å¤±è´¥: {e}")
                else:
                    st.session_state["confirm_clear_all"] = True
                    st.warning("ç¡®å®šè¦æ¸…é™¤å…¨éƒ¨å†å²è®°å½•å—ï¼Ÿå†æ¬¡ç‚¹å‡»æŒ‰é’®ç¡®è®¤ã€‚")
        
        # ä¸ºæ¯æ¡è®°å½•åˆ›å»ºä¸€è¡Œ
        for i, record in enumerate(history_list):
            # åˆ›å»ºä¸€è¡Œå¸ƒå±€
            col_info, col_view, col_delete = st.columns([8, 1, 1])
            
            # å·¦ä¾§ï¼šæ˜¾ç¤ºè®°å½•ä¿¡æ¯
            with col_info:
                st.markdown(f"**{record['run_id']}** | æ•°æ®é›†ç±»å‹ï¼š{record['model_argument']}|æ¨¡å‹: {record['model']} | æ•°æ®é›†: {record['dataset']} | ä»»åŠ¡: {record['task']}| æ•°æ®:{record['data']}")
            
            # ä¸­é—´ï¼šæŸ¥çœ‹ç»“æœæŒ‰é’®
            with col_view:
                view_key = f"view_{record['run_id']}"
                if st.button("æŸ¥çœ‹ç»“æœ", key=view_key):
                    # åˆ‡æ¢æŸ¥çœ‹çŠ¶æ€
                    st.session_state[f"show_{record['run_id']}"] = not st.session_state.get(f"show_{record['run_id']}", False)
            
            # å³ä¾§ï¼šåˆ é™¤æŒ‰é’®
            with col_delete:
                delete_key = f"delete_{record['run_id']}"
                if st.button("ğŸ—‘ï¸", key=delete_key, help="åˆ é™¤æ­¤è®°å½•"):
                    # ç¡®è®¤åˆ é™¤
                    if st.session_state.get(f"confirm_delete_{record['run_id']}", False):
                        # åˆ é™¤ç»“æœæ–‡ä»¶å¤¹
                        run_folder = os.path.join(project_root, 'results', 'results', record['run_id'])
                        if os.path.exists(run_folder):
                            try:
                                shutil.rmtree(run_folder)
                                st.success(f"å·²åˆ é™¤ç»“æœæ–‡ä»¶å¤¹: {run_folder}")
                            except Exception as e:
                                st.error(f"åˆ é™¤æ–‡ä»¶å¤¹å¤±è´¥: {e}")
                        
                        # ä»å†å²è®°å½•ä¸­ç§»é™¤
                        del history_list[i]
                        
                        # ä¿å­˜æ›´æ–°åçš„å†å²è®°å½•
                        with open(HISTORY_PATH, "w", encoding="utf-8") as f:
                            json.dump(history_list, f, indent=2, ensure_ascii=False)
                        
                        st.success("å†å²è®°å½•å·²åˆ é™¤ï¼")
                        st.rerun()
                    else:
                        # è®¾ç½®ç¡®è®¤æ ‡å¿—
                        st.session_state[f"confirm_delete_{record['run_id']}"] = True
                        st.warning("ç¡®å®šè¦åˆ é™¤è¿™æ¡è®°å½•å—ï¼Ÿå†æ¬¡ç‚¹å‡»åˆ é™¤æŒ‰é’®ç¡®è®¤ã€‚")
            
            # æ˜¾ç¤ºç»“æœåŒºåŸŸï¼ˆå¦‚æœè¯¥è®°å½•è¢«å±•å¼€ï¼‰
            if st.session_state.get(f"show_{record['run_id']}", False):
                selected_run_path = os.path.join(project_root, 'results', 'results', record["run_id"])
                
                if os.path.exists(selected_run_path):
                    if record.get("eval", True):
                        st.markdown("#### ğŸ–¼ï¸ æ¨¡å‹åˆ†æå›¾")
                        display_images_recursively(os.path.join(selected_run_path, "plots"))

                    st.markdown("#### ğŸ“Š æ¨¡å‹ç»“æœè¡¨æ ¼")
                    display_csv_tables(selected_run_path)
                else:
                    st.warning("æ‰¾ä¸åˆ°å¯¹åº”çš„å†å²ç›®å½•ã€‚")
                
                st.markdown("---")
        